{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29225dfe",
   "metadata": {},
   "source": [
    "# Classification - Adaptive Boosting (Best Hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b7341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e7845e",
   "metadata": {},
   "source": [
    "Normalised - Without outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15828d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.349487</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.580455</td>\n",
       "      <td>0.629251</td>\n",
       "      <td>-0.317312</td>\n",
       "      <td>0.263730</td>\n",
       "      <td>-0.974068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.149555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.241118</td>\n",
       "      <td>0.629251</td>\n",
       "      <td>-1.649552</td>\n",
       "      <td>-1.579747</td>\n",
       "      <td>-0.974068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.050377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.241118</td>\n",
       "      <td>-0.272192</td>\n",
       "      <td>0.082360</td>\n",
       "      <td>0.263730</td>\n",
       "      <td>1.211318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.681167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.857661</td>\n",
       "      <td>-0.973313</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.331039</td>\n",
       "      <td>-0.974068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.164882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.384988</td>\n",
       "      <td>-1.173634</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.331039</td>\n",
       "      <td>1.211318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181139</th>\n",
       "      <td>1.349487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.261522</td>\n",
       "      <td>0.979109</td>\n",
       "      <td>-0.628168</td>\n",
       "      <td>1.103451</td>\n",
       "      <td>1.211318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181140</th>\n",
       "      <td>1.349487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.241118</td>\n",
       "      <td>-0.172031</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>0.624467</td>\n",
       "      <td>-0.399610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181141</th>\n",
       "      <td>-0.727318</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.241061</td>\n",
       "      <td>1.025419</td>\n",
       "      <td>0.104564</td>\n",
       "      <td>0.763605</td>\n",
       "      <td>1.211318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>0.334160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.241118</td>\n",
       "      <td>0.045409</td>\n",
       "      <td>0.015748</td>\n",
       "      <td>-1.579747</td>\n",
       "      <td>1.211318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181143</th>\n",
       "      <td>1.349487</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.164762</td>\n",
       "      <td>0.192374</td>\n",
       "      <td>2.347168</td>\n",
       "      <td>0.263730</td>\n",
       "      <td>-0.578758</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181144 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "0       1.349487             0              1 -0.580455     0.629251   \n",
       "1       0.149555             0              0 -0.241118     0.629251   \n",
       "2      -1.050377             0              0 -0.241118    -0.272192   \n",
       "3      -0.681167             0              0 -0.857661    -0.973313   \n",
       "4       1.164882             1              1 -1.384988    -1.173634   \n",
       "...          ...           ...            ...       ...          ...   \n",
       "181139  1.349487             0              0 -0.261522     0.979109   \n",
       "181140  1.349487             0              0 -0.241118    -0.172031   \n",
       "181141 -0.727318             0              0 -0.241061     1.025419   \n",
       "181142  0.334160             0              0 -0.241118     0.045409   \n",
       "181143  1.349487             1              0 -0.164762     0.192374   \n",
       "\n",
       "        blood_glucose_level  smoking_history_encoded  gender_encoded  diabetes  \n",
       "0                 -0.317312                 0.263730       -0.974068         0  \n",
       "1                 -1.649552                -1.579747       -0.974068         0  \n",
       "2                  0.082360                 0.263730        1.211318         0  \n",
       "3                  0.015748                 0.331039       -0.974068         0  \n",
       "4                  0.015748                 0.331039        1.211318         0  \n",
       "...                     ...                      ...             ...       ...  \n",
       "181139            -0.628168                 1.103451        1.211318         1  \n",
       "181140             0.015748                 0.624467       -0.399610         1  \n",
       "181141             0.104564                 0.763605        1.211318         1  \n",
       "181142             0.015748                -1.579747        1.211318         1  \n",
       "181143             2.347168                 0.263730       -0.578758         1  \n",
       "\n",
       "[181144 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will be using the new_df_without_outliers_copy_smote_resampled.xlsx\n",
    "df_without_outlier = pd.read_excel('C:\\wamp64\\www\\IS424-Data-Mining\\Data_Set\\\\new_df_without_outliers_copy_smote_resampled.xlsx')\n",
    "df_without_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfb8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = df_without_outlier.drop(columns=['diabetes'])\n",
    "y = df_without_outlier['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b9faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa37577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AdaBoost Classifier\n",
    "adaboost_clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6743642",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Perform Grid Search\u001b[39;00m\n\u001b[0;32m      8\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39madaboost_clf, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Get Best Parameters\u001b[39;00m\n\u001b[0;32m     12\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    887\u001b[0m     )\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1391\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    860\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 680\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:486\u001b[0m, in \u001b[0;36mAdaBoostClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malgorithm \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:145\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    141\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iboost \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators):\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;66;03m# Boosting step\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m     sample_weight, estimator_weight, estimator_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;66;03m# Early termination\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:548\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;124;03m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSAMME.R\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_boost_real\u001b[49m\u001b[43m(\u001b[49m\u001b[43miboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[1;32mc:\\Users\\hazel\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:597\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    593\u001b[0m np\u001b[38;5;241m.\u001b[39mclip(proba, np\u001b[38;5;241m.\u001b[39mfinfo(proba\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39meps, \u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39mproba)\n\u001b[0;32m    595\u001b[0m \u001b[38;5;66;03m# Boost weight using multi-class AdaBoost SAMME.R alg\u001b[39;00m\n\u001b[0;32m    596\u001b[0m estimator_weight \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxlogy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_coding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_predict_proba\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# Only boost the weights if it will fit again\u001b[39;00m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m iboost \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;66;03m# Only boost positive weights\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of weak learners\n",
    "    'learning_rate': [0.1, 0.5, 1.0]  # Learning rate of the boosting process\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=adaboost_clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get Best Parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cae785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model with Best Parameters\n",
    "ada_classifier = AdaBoostClassifier(**best_params)\n",
    "ada_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Gradient Boosting classifier\n",
    "y_pred_ada = ada_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_ada)\n",
    "precision = precision_score(y_test, y_pred_ada)\n",
    "recall = recall_score(y_test, y_pred_ada)\n",
    "f1 = f1_score(y_test, y_pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a47adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Boosting Evaluation Report (Normalised w/o outlier):\n",
      "Accuracy: 0.9781666620663004\n",
      "Precision: 0.9928827649034903\n",
      "Recall: 0.9632125497127707\n",
      "F1-score: 0.9778226371716153\n"
     ]
    }
   ],
   "source": [
    "print(\"Adaptive Boosting Evaluation Report (Normalised w/o outlier):\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c5d4f",
   "metadata": {},
   "source": [
    "Normalised - Outlier Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf5e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930849</td>\n",
       "      <td>-0.357602</td>\n",
       "      <td>-1.154539</td>\n",
       "      <td>1.806645</td>\n",
       "      <td>-0.777719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.018012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.073804</td>\n",
       "      <td>-0.233789</td>\n",
       "      <td>0.206884</td>\n",
       "      <td>-0.280453</td>\n",
       "      <td>-0.777719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.656370</td>\n",
       "      <td>1.375782</td>\n",
       "      <td>-0.405756</td>\n",
       "      <td>-0.280453</td>\n",
       "      <td>-0.777719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.779506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.006045</td>\n",
       "      <td>-0.048069</td>\n",
       "      <td>-0.746112</td>\n",
       "      <td>-0.280453</td>\n",
       "      <td>1.417943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.256518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553214</td>\n",
       "      <td>-0.357602</td>\n",
       "      <td>-1.154539</td>\n",
       "      <td>-1.553924</td>\n",
       "      <td>-0.777719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6163</th>\n",
       "      <td>0.449954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.397771</td>\n",
       "      <td>-0.410728</td>\n",
       "      <td>-0.364914</td>\n",
       "      <td>-0.280453</td>\n",
       "      <td>-0.777719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>-0.874241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341732</td>\n",
       "      <td>-1.100480</td>\n",
       "      <td>-0.786955</td>\n",
       "      <td>-1.030285</td>\n",
       "      <td>-0.777719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>-2.108582</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585866</td>\n",
       "      <td>-0.225281</td>\n",
       "      <td>-1.399595</td>\n",
       "      <td>-1.009532</td>\n",
       "      <td>-0.777719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166</th>\n",
       "      <td>-0.640560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>-0.108843</td>\n",
       "      <td>-0.405756</td>\n",
       "      <td>-1.133316</td>\n",
       "      <td>-0.052526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>0.591901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.627652</td>\n",
       "      <td>-1.001929</td>\n",
       "      <td>-0.364914</td>\n",
       "      <td>0.629038</td>\n",
       "      <td>1.417943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6168 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "0     0.174516             0              0  0.930849    -0.357602   \n",
       "1    -1.018012             0              0  1.073804    -0.233789   \n",
       "2     0.949660             0              0  1.656370     1.375782   \n",
       "3    -0.779506             0              0  1.006045    -0.048069   \n",
       "4    -1.256518             0              0  0.553214    -0.357602   \n",
       "...        ...           ...            ...       ...          ...   \n",
       "6163  0.449954             0              0  0.397771    -0.410728   \n",
       "6164 -0.874241             0              0  0.341732    -1.100480   \n",
       "6165 -2.108582             0              0  0.585866    -0.225281   \n",
       "6166 -0.640560             0              0  0.629500    -0.108843   \n",
       "6167  0.591901             0              0  1.627652    -1.001929   \n",
       "\n",
       "      blood_glucose_level  smoking_history_encoded  gender_encoded  diabetes  \n",
       "0               -1.154539                 1.806645       -0.777719         0  \n",
       "1                0.206884                -0.280453       -0.777719         0  \n",
       "2               -0.405756                -0.280453       -0.777719         1  \n",
       "3               -0.746112                -0.280453        1.417943         0  \n",
       "4               -1.154539                -1.553924       -0.777719         0  \n",
       "...                   ...                      ...             ...       ...  \n",
       "6163            -0.364914                -0.280453       -0.777719         0  \n",
       "6164            -0.786955                -1.030285       -0.777719         0  \n",
       "6165            -1.399595                -1.009532       -0.777719         0  \n",
       "6166            -0.405756                -1.133316       -0.052526         0  \n",
       "6167            -0.364914                 0.629038        1.417943         0  \n",
       "\n",
       "[6168 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will be using the new_df_without_outliers_copy_smote_resampled.xlsx\n",
    "df_outlier = pd.read_excel('C:\\wamp64\\www\\IS424-Data-Mining\\Data_Set\\\\new_df_outliers_only_copy_smote_resampled.xlsx')\n",
    "df_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = df_outlier.drop(columns=['diabetes'])\n",
    "y = df_outlier['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921d8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23dab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AdaBoost Classifier\n",
    "adaboost_clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5918d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of weak learners\n",
    "    'learning_rate': [0.1, 0.5, 1.0]  # Learning rate of the boosting process\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=adaboost_clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get Best Parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855c008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.5, n_estimators=100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model with Best Parameters\n",
    "ada_classifier = AdaBoostClassifier(**best_params)\n",
    "ada_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Adaptive Boosting classifier\n",
    "y_pred_gb = ada_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "precision = precision_score(y_test, y_pred_gb)\n",
    "recall = recall_score(y_test, y_pred_gb)\n",
    "f1 = f1_score(y_test, y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d7d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Boosting Evaluation Report (Normalised outliers only):\n",
      "Accuracy: 0.9821717990275527\n",
      "Precision: 0.9950738916256158\n",
      "Recall: 0.9696\n",
      "F1-score: 0.9821717990275526\n"
     ]
    }
   ],
   "source": [
    "print(\"Adaptive Boosting Evaluation Report (Normalised outliers only):\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f48dbe",
   "metadata": {},
   "source": [
    "Not Normalised - Without Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48285d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.190000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>140</td>\n",
       "      <td>0.131757</td>\n",
       "      <td>-0.128959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>80</td>\n",
       "      <td>-0.797024</td>\n",
       "      <td>-0.128959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>158</td>\n",
       "      <td>0.131757</td>\n",
       "      <td>0.160772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.450000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>155</td>\n",
       "      <td>0.165669</td>\n",
       "      <td>-0.128959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.140000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>155</td>\n",
       "      <td>0.165669</td>\n",
       "      <td>0.160772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181139</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.191924</td>\n",
       "      <td>6.949298</td>\n",
       "      <td>126</td>\n",
       "      <td>0.554826</td>\n",
       "      <td>0.160772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181140</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>155</td>\n",
       "      <td>0.313504</td>\n",
       "      <td>-0.052799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181141</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.320357</td>\n",
       "      <td>6.995535</td>\n",
       "      <td>159</td>\n",
       "      <td>0.383605</td>\n",
       "      <td>0.160772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>6.017092</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.797024</td>\n",
       "      <td>0.160772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181143</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.799284</td>\n",
       "      <td>6.163822</td>\n",
       "      <td>260</td>\n",
       "      <td>0.131757</td>\n",
       "      <td>-0.076550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181144 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  hypertension  heart_disease        bmi  HbA1c_level  \\\n",
       "0       80.0             0              1  25.190000     6.600000   \n",
       "1       54.0             0              0  27.320000     6.600000   \n",
       "2       28.0             0              0  27.320000     5.700000   \n",
       "3       36.0             0              0  23.450000     5.000000   \n",
       "4       76.0             1              1  20.140000     4.800000   \n",
       "...      ...           ...            ...        ...          ...   \n",
       "181139  80.0             0              0  27.191924     6.949298   \n",
       "181140  80.0             0              0  27.320000     5.800000   \n",
       "181141  35.0             0              0  27.320357     6.995535   \n",
       "181142  58.0             0              0  27.320000     6.017092   \n",
       "181143  80.0             1              0  27.799284     6.163822   \n",
       "\n",
       "        blood_glucose_level  smoking_history_encoded  gender_encoded  diabetes  \n",
       "0                       140                 0.131757       -0.128959         0  \n",
       "1                        80                -0.797024       -0.128959         0  \n",
       "2                       158                 0.131757        0.160772         0  \n",
       "3                       155                 0.165669       -0.128959         0  \n",
       "4                       155                 0.165669        0.160772         0  \n",
       "...                     ...                      ...             ...       ...  \n",
       "181139                  126                 0.554826        0.160772         1  \n",
       "181140                  155                 0.313504       -0.052799         1  \n",
       "181141                  159                 0.383605        0.160772         1  \n",
       "181142                  155                -0.797024        0.160772         1  \n",
       "181143                  260                 0.131757       -0.076550         1  \n",
       "\n",
       "[181144 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_outlier_notnorm = pd.read_csv('C:\\wamp64\\www\\IS424-Data-Mining\\Data_Set\\\\new_df_without_outliers_copy_smote_resampled_noNormalised.csv')\n",
    "df_without_outlier_notnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = df_without_outlier_notnorm.drop(columns=['diabetes'])\n",
    "y = df_without_outlier_notnorm['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33b1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AdaBoost Classifier\n",
    "adaboost_clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba10f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 1.0, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of weak learners\n",
    "    'learning_rate': [0.1, 0.5, 1.0]  # Learning rate of the boosting process\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=adaboost_clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get Best Parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79c974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model with Best Parameters\n",
    "ada_classifier = AdaBoostClassifier(**best_params)\n",
    "ada_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e526756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Gradient Boosting classifier\n",
    "y_pred_gb = ada_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "precision = precision_score(y_test, y_pred_gb)\n",
    "recall = recall_score(y_test, y_pred_gb)\n",
    "f1 = f1_score(y_test, y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef300559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Boosting Evaluation Report (Not Normalised w/o outlier):\n",
      "Accuracy: 0.9780838554748958\n",
      "Precision: 0.9926571038251366\n",
      "Recall: 0.9632677861246134\n",
      "F1-score: 0.9777416461089932\n"
     ]
    }
   ],
   "source": [
    "print(\"Adaptive Boosting Evaluation Report (Not Normalised w/o outlier):\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c3c0f",
   "metadata": {},
   "source": [
    "Not Normalised - Outliers Only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02678d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.700000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>0.310171</td>\n",
       "      <td>-0.310005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.430000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.052540</td>\n",
       "      <td>-0.310005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.480000</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.052540</td>\n",
       "      <td>-0.310005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.610000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>130</td>\n",
       "      <td>-0.052540</td>\n",
       "      <td>0.561670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.130000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>-0.273853</td>\n",
       "      <td>-0.310005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6163</th>\n",
       "      <td>58.619390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.248887</td>\n",
       "      <td>5.914183</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.052540</td>\n",
       "      <td>-0.310005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>36.411190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.570729</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>127</td>\n",
       "      <td>-0.182851</td>\n",
       "      <td>-0.310005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>15.709946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.525147</td>\n",
       "      <td>6.213743</td>\n",
       "      <td>82</td>\n",
       "      <td>-0.179245</td>\n",
       "      <td>-0.310005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166</th>\n",
       "      <td>40.330285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.053191</td>\n",
       "      <td>6.401829</td>\n",
       "      <td>155</td>\n",
       "      <td>-0.200757</td>\n",
       "      <td>-0.022104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.132468</td>\n",
       "      <td>4.959194</td>\n",
       "      <td>158</td>\n",
       "      <td>0.105518</td>\n",
       "      <td>0.561670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6168 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  hypertension  heart_disease        bmi  HbA1c_level  \\\n",
       "0     54.000000             0              0  54.700000     6.000000   \n",
       "1     34.000000             0              0  56.430000     6.200000   \n",
       "2     67.000000             0              0  63.480000     8.800000   \n",
       "3     38.000000             0              0  55.610000     6.500000   \n",
       "4     30.000000             0              0  50.130000     6.000000   \n",
       "...         ...           ...            ...        ...          ...   \n",
       "6163  58.619390             0              0  48.248887     5.914183   \n",
       "6164  36.411190             0              0  47.570729     4.800000   \n",
       "6165  15.709946             0              0  50.525147     6.213743   \n",
       "6166  40.330285             0              0  51.053191     6.401829   \n",
       "6167  61.000000             0              0  63.132468     4.959194   \n",
       "\n",
       "      blood_glucose_level  smoking_history_encoded  gender_encoded  diabetes  \n",
       "0                     100                 0.310171       -0.310005         0  \n",
       "1                     200                -0.052540       -0.310005         0  \n",
       "2                     155                -0.052540       -0.310005         1  \n",
       "3                     130                -0.052540        0.561670         0  \n",
       "4                     100                -0.273853       -0.310005         0  \n",
       "...                   ...                      ...             ...       ...  \n",
       "6163                  158                -0.052540       -0.310005         0  \n",
       "6164                  127                -0.182851       -0.310005         0  \n",
       "6165                   82                -0.179245       -0.310005         0  \n",
       "6166                  155                -0.200757       -0.022104         0  \n",
       "6167                  158                 0.105518        0.561670         0  \n",
       "\n",
       "[6168 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlier_notnorm = pd.read_csv('C:\\wamp64\\www\\IS424-Data-Mining\\Data_Set\\\\new_df_outliers_only_copy_smote_resampled_noNormalised.csv')\n",
    "df_outlier_notnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variable\n",
    "X = df_outlier_notnorm.drop(columns=['diabetes'])\n",
    "y = df_outlier_notnorm['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17993d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfb6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AdaBoost Classifier\n",
    "adaboost_clf = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f71aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of weak learners\n",
    "    'learning_rate': [0.1, 0.5, 1.0]  # Learning rate of the boosting process\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=adaboost_clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get Best Parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c7b68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdaBoostClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train Model with Best Parameters\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ada_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mAdaBoostClassifier\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_params, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m ada_classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AdaBoostClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Train Model with Best Parameters\n",
    "ada_classifier = AdaBoostClassifier(**best_params, random_state=42)\n",
    "ada_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Gradient Boosting classifier\n",
    "y_pred_gb = ada_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "precision = precision_score(y_test, y_pred_gb)\n",
    "recall = recall_score(y_test, y_pred_gb)\n",
    "f1 = f1_score(y_test, y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd166f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Boosting Evaluation Report (Not Normalised outliers only):\n",
      "Accuracy: 0.9821717990275527\n",
      "Precision: 0.9950738916256158\n",
      "Recall: 0.9696\n",
      "F1-score: 0.9821717990275526\n"
     ]
    }
   ],
   "source": [
    "print(\"Adaptive Boosting Evaluation Report (Not Normalised outliers only):\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
