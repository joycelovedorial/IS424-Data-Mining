{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c118e0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import BisectingKMeans\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "plt.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183b8ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.692577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321051</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>-1.426157</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.616779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.161089</td>\n",
       "      <td>0.489869</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.261494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.583225</td>\n",
       "      <td>-0.492714</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>0</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.514935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.081957</td>\n",
       "      <td>-0.679515</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>0</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "0  1.692577             0              1 -0.321051     1.001692   \n",
       "1  0.537899             0              0 -0.000114     1.001692   \n",
       "2 -0.616779             0              0 -0.000114     0.161089   \n",
       "3 -0.261494             0              0 -0.583225    -0.492714   \n",
       "4  1.514935             1              1 -1.081957    -0.679515   \n",
       "\n",
       "   blood_glucose_level  diabetes  smoking_history_encoded  gender_encoded  \n",
       "0             0.047709         0                -0.640425       -0.841175  \n",
       "1            -1.426157         0                -0.640425       -0.841175  \n",
       "2             0.489869         0                -0.640425        1.188813  \n",
       "3             0.416175         0                 1.561464       -0.841175  \n",
       "4             0.416175         0                 1.561464        1.188813  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/varalam/Downloads/Original Dataset with Outliers Included Normalized.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2055da8",
   "metadata": {},
   "source": [
    "<h1>SMOTE Oversampling</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7931b8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes:  8500\n",
      "No:  91482\n"
     ]
    }
   ],
   "source": [
    "is_diabetic = df[\"diabetes\"].value_counts()\n",
    "print(\"Yes: \",is_diabetic[1])\n",
    "print(\"No: \",is_diabetic[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c509f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy of df before doing SMOTE oversampling\n",
    "new_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786b8341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = new_df.drop(\"diabetes\", axis=1)\n",
    "y = new_df[\"diabetes\"]\n",
    "\n",
    "# Initialize SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=424)\n",
    "\n",
    "# Apply SMOTE to the dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Count the occurrences of each class in the original dataset\n",
    "original_class_counts = new_df[\"diabetes\"].value_counts()\n",
    "\n",
    "# Calculate the percentage of each class\n",
    "original_percentages = original_class_counts / len(new_df) * 100\n",
    "\n",
    "# Count the occurrences of each class in the resampled dataset\n",
    "resampled_class_counts = pd.Series(y_resampled).value_counts()\n",
    "\n",
    "# Calculate the percentage of each class\n",
    "resampled_percentages = resampled_class_counts / len(y_resampled) * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Bar chart for original and SMOTE resampled class distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "bars_1 = plt.bar(original_class_counts.index, original_class_counts.values, color=['violet', 'yellow'])\n",
    "for bar, label in zip(bars_1, original_percentages):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5, f'{label:.2f}%', ha='center', va='bottom')\n",
    "plt.title('Original Diabetes Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(original_class_counts.index, ['0', '1'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bars_2 = plt.bar(resampled_class_counts.index, resampled_class_counts.values, color=['violet', 'yellow'])\n",
    "for bar, label in zip(bars_2, resampled_percentages):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5, f'{label:.2f}%', ha='center', va='bottom')\n",
    "plt.title('SMOTE Resampled Diabetes Class Distribution for Dataframe Without Outliers')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8feb4585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the SMOTE resampled data\n",
    "df_resampled = pd.DataFrame(data=X_resampled, columns=X.columns)\n",
    "df_resampled[\"diabetes\"] = y_resampled\n",
    "\n",
    "df_resampled_bisect = df_resampled.copy()\n",
    "df_resampled_imp = df_resampled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1ee87",
   "metadata": {},
   "source": [
    "<h1>KMeans Clustering<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d8eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_resampled.iloc[:, 0:8]\n",
    "y = df_resampled.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a3ddb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.692577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321051</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>-1.426157</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.616779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.161089</td>\n",
       "      <td>0.489869</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.261494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.583225</td>\n",
       "      <td>-0.492714</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.514935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.081957</td>\n",
       "      <td>-0.679515</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182959</th>\n",
       "      <td>1.348876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073653</td>\n",
       "      <td>0.932655</td>\n",
       "      <td>0.506959</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182960</th>\n",
       "      <td>1.242402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.496150</td>\n",
       "      <td>0.593863</td>\n",
       "      <td>2.995441</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182961</th>\n",
       "      <td>1.156268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391953</td>\n",
       "      <td>0.615763</td>\n",
       "      <td>0.514433</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182962</th>\n",
       "      <td>0.550334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117714</td>\n",
       "      <td>0.228337</td>\n",
       "      <td>0.136141</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182963</th>\n",
       "      <td>0.624785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.472269</td>\n",
       "      <td>3.184417</td>\n",
       "      <td>1.521575</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182964 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "0       1.692577             0              1 -0.321051     1.001692   \n",
       "1       0.537899             0              0 -0.000114     1.001692   \n",
       "2      -0.616779             0              0 -0.000114     0.161089   \n",
       "3      -0.261494             0              0 -0.583225    -0.492714   \n",
       "4       1.514935             1              1 -1.081957    -0.679515   \n",
       "...          ...           ...            ...       ...          ...   \n",
       "182959  1.348876             0              0  0.073653     0.932655   \n",
       "182960  1.242402             1              0  1.496150     0.593863   \n",
       "182961  1.156268             0              0  0.391953     0.615763   \n",
       "182962  0.550334             0              0  0.117714     0.228337   \n",
       "182963  0.624785             1              0  1.472269     3.184417   \n",
       "\n",
       "        blood_glucose_level  smoking_history_encoded  gender_encoded  clusters  \n",
       "0                  0.047709                -0.640425       -0.841175         1  \n",
       "1                 -1.426157                -0.640425       -0.841175         1  \n",
       "2                  0.489869                -0.640425        1.188813         3  \n",
       "3                  0.416175                 1.561464       -0.841175         2  \n",
       "4                  0.416175                 1.561464        1.188813         2  \n",
       "...                     ...                      ...             ...       ...  \n",
       "182959             0.506959                -0.640425        1.188813         1  \n",
       "182960             2.995441                -0.640425       -0.841175         4  \n",
       "182961             0.514433                -0.640425       -0.841175         1  \n",
       "182962             0.136141                 1.561464        1.188813         2  \n",
       "182963             1.521575                 1.561464        1.188813         4  \n",
       "\n",
       "[182964 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit KMeans model\n",
    "model=KMeans(n_clusters=4, n_init=10, random_state=424)\n",
    "model.fit(X)\n",
    "\n",
    "labels=model.labels_ + 1\n",
    "labels  #clustering into 2 groups: 0 and 1\n",
    "\n",
    "centers=model.cluster_centers_\n",
    "centers\n",
    "\n",
    "model.inertia_\n",
    "\n",
    "X['clusters']=labels\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e6ee2",
   "metadata": {},
   "source": [
    "<h1>Elbow Plot of KMeans Clustering<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b279ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inertia_train={}\n",
    "for n_cluster in range(1,10):\n",
    "    model=KMeans(n_clusters=n_cluster, n_init=10)\n",
    "    model.fit(X)\n",
    "    inertia_train[n_cluster]=model.inertia_\n",
    "    \n",
    "plt.plot(range(1,10),inertia_train.values())\n",
    "plt.xlabel('The number of clusters') #inertia is the measure of each dots to its centers: tight clusters, low inertia\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aa27db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.692577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321051</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>-1.426157</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.616779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.161089</td>\n",
       "      <td>0.489869</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.261494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.583225</td>\n",
       "      <td>-0.492714</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.514935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.081957</td>\n",
       "      <td>-0.679515</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182959</th>\n",
       "      <td>1.348876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073653</td>\n",
       "      <td>0.932655</td>\n",
       "      <td>0.506959</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182960</th>\n",
       "      <td>1.242402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.496150</td>\n",
       "      <td>0.593863</td>\n",
       "      <td>2.995441</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182961</th>\n",
       "      <td>1.156268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391953</td>\n",
       "      <td>0.615763</td>\n",
       "      <td>0.514433</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182962</th>\n",
       "      <td>0.550334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117714</td>\n",
       "      <td>0.228337</td>\n",
       "      <td>0.136141</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182963</th>\n",
       "      <td>0.624785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.472269</td>\n",
       "      <td>3.184417</td>\n",
       "      <td>1.521575</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182964 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "0       1.692577             0              1 -0.321051     1.001692   \n",
       "1       0.537899             0              0 -0.000114     1.001692   \n",
       "2      -0.616779             0              0 -0.000114     0.161089   \n",
       "3      -0.261494             0              0 -0.583225    -0.492714   \n",
       "4       1.514935             1              1 -1.081957    -0.679515   \n",
       "...          ...           ...            ...       ...          ...   \n",
       "182959  1.348876             0              0  0.073653     0.932655   \n",
       "182960  1.242402             1              0  1.496150     0.593863   \n",
       "182961  1.156268             0              0  0.391953     0.615763   \n",
       "182962  0.550334             0              0  0.117714     0.228337   \n",
       "182963  0.624785             1              0  1.472269     3.184417   \n",
       "\n",
       "        blood_glucose_level  smoking_history_encoded  gender_encoded  \\\n",
       "0                  0.047709                -0.640425       -0.841175   \n",
       "1                 -1.426157                -0.640425       -0.841175   \n",
       "2                  0.489869                -0.640425        1.188813   \n",
       "3                  0.416175                 1.561464       -0.841175   \n",
       "4                  0.416175                 1.561464        1.188813   \n",
       "...                     ...                      ...             ...   \n",
       "182959             0.506959                -0.640425        1.188813   \n",
       "182960             2.995441                -0.640425       -0.841175   \n",
       "182961             0.514433                -0.640425       -0.841175   \n",
       "182962             0.136141                 1.561464        1.188813   \n",
       "182963             1.521575                 1.561464        1.188813   \n",
       "\n",
       "        diabetes  clusters  \n",
       "0              0         1  \n",
       "1              0         1  \n",
       "2              0         3  \n",
       "3              0         2  \n",
       "4              0         2  \n",
       "...          ...       ...  \n",
       "182959         1         1  \n",
       "182960         1         4  \n",
       "182961         1         1  \n",
       "182962         1         2  \n",
       "182963         1         4  \n",
       "\n",
       "[182964 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the 'clusters' column to the original DataFrame\n",
    "df_resampled['clusters'] = X['clusters']\n",
    "\n",
    "# Display the DataFrame with added 'clusters' column\n",
    "df_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d43e26",
   "metadata": {},
   "source": [
    "<h1> Logistic Prediction on different Cluster groups <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7018cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over unique cluster values\n",
    "for cluster_value in df_resampled['clusters'].unique():\n",
    "    # Create a DataFrame for the current cluster\n",
    "    cluster_idx = df_resampled[df_resampled['clusters'] == cluster_value].copy()\n",
    "    \n",
    "    # Create a variable for the current DataFrame\n",
    "    globals()[f'cluster_{cluster_value}'] = cluster_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d848c946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.360256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.161089</td>\n",
       "      <td>2.995441</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.261494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.745725</td>\n",
       "      <td>0.628091</td>\n",
       "      <td>2.012863</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.804363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.842295</td>\n",
       "      <td>3.978018</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1.692577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.188493</td>\n",
       "      <td>3.486729</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.559345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659841</td>\n",
       "      <td>0.908292</td>\n",
       "      <td>3.486729</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182951</th>\n",
       "      <td>0.613412</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.515383</td>\n",
       "      <td>3.168663</td>\n",
       "      <td>2.012863</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182955</th>\n",
       "      <td>0.506408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.598392</td>\n",
       "      <td>0.677823</td>\n",
       "      <td>1.862287</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182958</th>\n",
       "      <td>1.692577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>3.243301</td>\n",
       "      <td>2.494119</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182960</th>\n",
       "      <td>1.242402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.496150</td>\n",
       "      <td>0.593863</td>\n",
       "      <td>2.995441</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182963</th>\n",
       "      <td>0.624785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.472269</td>\n",
       "      <td>3.184417</td>\n",
       "      <td>1.521575</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36502 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "38      0.360256             1              0 -0.000114     0.161089   \n",
       "87     -0.261494             0              0  0.745725     0.628091   \n",
       "94      0.804363             0              0 -0.000114     1.842295   \n",
       "104     1.692577             1              0 -0.000114     1.188493   \n",
       "125     1.559345             0              0  0.659841     0.908292   \n",
       "...          ...           ...            ...       ...          ...   \n",
       "182951  0.613412             0              0  1.515383     3.168663   \n",
       "182955  0.506408             0              0  2.598392     0.677823   \n",
       "182958  1.692577             1              0  0.000194     3.243301   \n",
       "182960  1.242402             1              0  1.496150     0.593863   \n",
       "182963  0.624785             1              0  1.472269     3.184417   \n",
       "\n",
       "        blood_glucose_level  smoking_history_encoded  gender_encoded  \\\n",
       "38                 2.995441                 1.561464        1.188813   \n",
       "87                 2.012863                 1.561464       -0.841175   \n",
       "94                 3.978018                -0.640425       -0.841175   \n",
       "104                3.486729                -0.640425       -0.841175   \n",
       "125                3.486729                -0.640425       -0.841175   \n",
       "...                     ...                      ...             ...   \n",
       "182951             2.012863                 1.561464       -0.841175   \n",
       "182955             1.862287                -0.640425        1.188813   \n",
       "182958             2.494119                -0.640425        1.188813   \n",
       "182960             2.995441                -0.640425       -0.841175   \n",
       "182963             1.521575                 1.561464        1.188813   \n",
       "\n",
       "        diabetes  clusters  \n",
       "38             1         4  \n",
       "87             1         4  \n",
       "94             1         4  \n",
       "104            1         4  \n",
       "125            1         4  \n",
       "...          ...       ...  \n",
       "182951         1         4  \n",
       "182955         1         4  \n",
       "182958         1         4  \n",
       "182960         1         4  \n",
       "182963         1         4  \n",
       "\n",
       "[36502 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94b5f131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8332515939185875\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83      7021\n",
      "           1       0.83      0.84      0.84      7252\n",
      "\n",
      "    accuracy                           0.83     14273\n",
      "   macro avg       0.83      0.83      0.83     14273\n",
      "weighted avg       0.83      0.83      0.83     14273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_cluster_2 = cluster_2.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_2 = X_cluster_2.drop('clusters', axis = 1)\n",
    "y_cluster_2 = cluster_2['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_2, X_test_cluster_2, y_train_cluster_2, y_test_cluster_2 = train_test_split(X_cluster_2, y_cluster_2, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_2 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_2.fit(X_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_2 = logreg_2.predict(X_test_cluster_2)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_2, predictions_2)\n",
    "classification_rep = classification_report(y_test_cluster_2, predictions_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aed01b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9744525547445255\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99     13604\n",
      "           1       0.93      0.04      0.07       370\n",
      "\n",
      "    accuracy                           0.97     13974\n",
      "   macro avg       0.95      0.52      0.53     13974\n",
      "weighted avg       0.97      0.97      0.96     13974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_cluster_3 = cluster_3.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_3 = X_cluster_3.drop('clusters', axis = 1)\n",
    "y_cluster_3 = cluster_3['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_3, X_test_cluster_3, y_train_cluster_3, y_test_cluster_3 = train_test_split(X_cluster_3, y_cluster_3, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_3 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_3.fit(X_train_cluster_3, y_train_cluster_3)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_3 = logreg_3.predict(X_test_cluster_3)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_3, predictions_3)\n",
    "classification_rep = classification_report(y_test_cluster_3, predictions_3)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ac12cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7716816414962085\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74      6789\n",
      "           1       0.80      0.79      0.80      8904\n",
      "\n",
      "    accuracy                           0.77     15693\n",
      "   macro avg       0.77      0.77      0.77     15693\n",
      "weighted avg       0.77      0.77      0.77     15693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_cluster_1 = cluster_1.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_1 = X_cluster_1.drop('clusters', axis = 1)\n",
    "y_cluster_1 = cluster_1['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_1, X_test_cluster_1, y_train_cluster_1, y_test_cluster_1 = train_test_split(X_cluster_1, y_cluster_1, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_1 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_1.fit(X_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_1 = logreg_1.predict(X_test_cluster_1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_1, predictions_1)\n",
    "classification_rep = classification_report(y_test_cluster_1, predictions_1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c561188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.8526593686702019\n",
      "Ensemble Model Precision: 0.8518609781626313\n",
      "Ensemble Model Recall: 0.8526593686702019\n",
      "Ensemble Model f1: 0.8521065823263883\n",
      "Ensemble Model AUC ROC: 0.8389821377749979\n",
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88     27543\n",
      "           1       0.81      0.79      0.80     16396\n",
      "\n",
      "    accuracy                           0.85     43939\n",
      "   macro avg       0.84      0.84      0.84     43939\n",
      "weighted avg       0.85      0.85      0.85     43939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Combine features and labels from all clusters\n",
    "X_combined = np.concatenate((X_cluster_1, X_cluster_3, X_cluster_2), axis=0)\n",
    "y_combined = np.concatenate((y_cluster_1, y_cluster_3, y_cluster_2), axis=0)\n",
    "\n",
    "# Split the combined data into training and test sets\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(X_combined, y_combined, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1', logreg_1), ('cluster_3', logreg_3), ('cluster_2', logreg_2)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the combined training set\n",
    "voting_clf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Make predictions using the ensemble model on the combined test set\n",
    "ensemble_predictions = voting_clf.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y_test_combined, ensemble_predictions)\n",
    "# Calculate precision\n",
    "precision_ensemble = precision_score(y_test_combined, ensemble_predictions, average='weighted')\n",
    "# Calculate recall\n",
    "recall_ensemble = recall_score(y_test_combined, ensemble_predictions, average='weighted')\n",
    "# Calculate F1-score\n",
    "f1_ensemble = f1_score(y_test_combined, ensemble_predictions, average='weighted')\n",
    "# Calculate the AUC score\n",
    "auc_ensemble = roc_auc_score(y_test_combined, ensemble_predictions)\n",
    "\n",
    "\n",
    "\n",
    "classification_report_ensemble = classification_report(y_test_combined, ensemble_predictions)\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble}\")\n",
    "print(f\"Ensemble Model Precision: {precision_ensemble}\")\n",
    "print(f\"Ensemble Model Recall: {recall_ensemble}\")\n",
    "print(f\"Ensemble Model f1: {f1_ensemble}\")\n",
    "print(f\"Ensemble Model AUC ROC: {auc_ensemble}\")\n",
    "print(\"Ensemble Model Classification Report:\")\n",
    "print(classification_report_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e538255",
   "metadata": {},
   "source": [
    "<h1>Random Forests model on clusters<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43c87af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model 1 Accuracy: 0.9550117886955968\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      6789\n",
      "           1       0.95      0.97      0.96      8904\n",
      "\n",
      "    accuracy                           0.96     15693\n",
      "   macro avg       0.96      0.95      0.95     15693\n",
      "weighted avg       0.96      0.96      0.95     15693\n",
      "\n",
      "Cross-validated Accuracy Scores: [0.95479995 0.95288816 0.95466339 0.94920115 0.95165916]\n",
      "Mean Cross-validated Accuracy: 0.9526423596886522\n"
     ]
    }
   ],
   "source": [
    "# Create and train the first Random Forest model\n",
    "rf_model1 = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model1.fit(X_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf1 = rf_model1.predict(X_test_cluster_1)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf1 = accuracy_score(y_test_cluster_1, y_pred_rf1)\n",
    "print(\"Random Forest Model 1 Accuracy:\", accuracy_rf1)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_1, y_pred_rf1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model1, X_train_cluster_1, y_train_cluster_1, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e89e352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model 1 Accuracy: 0.9634975127863799\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      7021\n",
      "           1       0.96      0.97      0.96      7252\n",
      "\n",
      "    accuracy                           0.96     14273\n",
      "   macro avg       0.96      0.96      0.96     14273\n",
      "weighted avg       0.96      0.96      0.96     14273\n",
      "\n",
      "Cross-validated Accuracy Scores: [0.95766401 0.95571236 0.9570635  0.95525526 0.95525526]\n",
      "Mean Cross-validated Accuracy: 0.9561900768806639\n"
     ]
    }
   ],
   "source": [
    "# Create and train the first Random Forest model\n",
    "rf_model2 = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model2.fit(X_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf2 = rf_model2.predict(X_test_cluster_2)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf2 = accuracy_score(y_test_cluster_2, y_pred_rf2)\n",
    "print(\"Random Forest Model 1 Accuracy:\", accuracy_rf2)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_2, y_pred_rf2)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model2, X_train_cluster_2, y_train_cluster_2, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Accuracy:\", cv_scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c6462d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model 3 Accuracy: 0.9939172749391727\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     13604\n",
      "           1       0.97      0.79      0.87       370\n",
      "\n",
      "    accuracy                           0.99     13974\n",
      "   macro avg       0.98      0.90      0.94     13974\n",
      "weighted avg       0.99      0.99      0.99     13974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train the first Random Forest model\n",
    "rf_model3 = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model3.fit(X_train_cluster_3, y_train_cluster_3)\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf3 = rf_model3.predict(X_test_cluster_3)\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf3 = accuracy_score(y_test_cluster_3, y_pred_rf3)\n",
    "print(\"Random Forest Model 3 Accuracy:\", accuracy_rf3)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_3, y_pred_rf3)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3e2d830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model 4 Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00     10951\n",
      "\n",
      "    accuracy                           1.00     10951\n",
      "   macro avg       1.00      1.00      1.00     10951\n",
      "weighted avg       1.00      1.00      1.00     10951\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_cluster_4 = cluster_4.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_4 = X_cluster_4.drop('clusters', axis = 1)\n",
    "y_cluster_4 = cluster_4['diabetes']  # Target variable\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_4, X_test_cluster_4, y_train_cluster_4, y_test_cluster_4 = train_test_split(X_cluster_4, y_cluster_4, test_size=0.3, random_state=424)\n",
    "\n",
    "\n",
    "\n",
    "# Create and train the first Random Forest model\n",
    "rf_model4 = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "\n",
    "rf_model4.fit(X_train_cluster_4, y_train_cluster_4)\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf4 = rf_model4.predict(X_test_cluster_4)\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf4 = accuracy_score(y_test_cluster_4, y_pred_rf4)\n",
    "print(\"Random Forest Model 4 Accuracy:\", accuracy_rf4)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_4, y_pred_rf4)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "863ebb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.97602477682638\n",
      "Ensemble Model Precision: 0.9760309150313308\n",
      "Ensemble Model Recall: 0.97602477682638\n",
      "Ensemble Model F1-score: 0.9760247347152929\n",
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     27467\n",
      "           1       0.97      0.98      0.98     27423\n",
      "\n",
      "    accuracy                           0.98     54890\n",
      "   macro avg       0.98      0.98      0.98     54890\n",
      "weighted avg       0.98      0.98      0.98     54890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Combine features and labels from all clusters\n",
    "X_combined_rf = np.concatenate((X_cluster_1, X_cluster_2, X_cluster_3, X_cluster_4), axis=0)\n",
    "y_combined_rf = np.concatenate((y_cluster_1, y_cluster_2, y_cluster_3, y_cluster_4), axis=0)\n",
    "\n",
    "# Split the combined_rf data into training and test sets\n",
    "X_train_combined_rf, X_test_combined_rf, y_train_combined_rf, y_test_combined_rf = train_test_split(X_combined_rf, y_combined_rf, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1', rf_model1), ('cluster_2', rf_model2), ('cluster_3', rf_model3), ('cluster_4', rf_model4)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the combined_rf training set\n",
    "voting_clf.fit(X_train_combined_rf, y_train_combined_rf)\n",
    "\n",
    "# Make predictions using the ensemble model on the combined_rf test set\n",
    "ensemble_predictions = voting_clf.predict(X_test_combined_rf)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y_test_combined_rf, ensemble_predictions)\n",
    "\n",
    "\n",
    "# Calculate precision\n",
    "precision_ensemble = precision_score(y_test_combined_rf, ensemble_predictions, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_ensemble = recall_score(y_test_combined_rf, ensemble_predictions, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_ensemble = f1_score(y_test_combined_rf, ensemble_predictions, average='weighted')\n",
    "\n",
    "\n",
    "classification_report_ensemble = classification_report(y_test_combined_rf, ensemble_predictions)\n",
    "\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble}\")\n",
    "print(f\"Ensemble Model Precision: {precision_ensemble}\")\n",
    "print(f\"Ensemble Model Recall: {recall_ensemble}\")\n",
    "print(f\"Ensemble Model F1-score: {f1_ensemble}\")\n",
    "\n",
    "\n",
    "print(\"Ensemble Model Classification Report:\")\n",
    "print(classification_report_ensemble)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "668c9dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model AUC-ROC: 0.9975050275013776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Fit the VotingClassifier on the combined_rf training set\n",
    "voting_clf.fit(X_train_combined_rf, y_train_combined_rf)\n",
    "\n",
    "# Initialize an empty array to store the predicted probabilities\n",
    "ensemble_probabilities = np.zeros((len(X_test_combined_rf), 2))  # Assuming binary classification\n",
    "\n",
    "# Iterate over individual models in the ensemble\n",
    "for estimator in voting_clf.estimators_:\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    class_probabilities = estimator.predict_proba(X_test_combined_rf)\n",
    "    # Aggregate the predicted probabilities\n",
    "    ensemble_probabilities += class_probabilities\n",
    "\n",
    "# Take the average of the predicted probabilities\n",
    "ensemble_probabilities /= len(voting_clf.estimators_)\n",
    "\n",
    "# Extract the probabilities for the positive class (assuming binary classification)\n",
    "positive_class_probabilities = ensemble_probabilities[:, 1]\n",
    "\n",
    "# Now you can use positive_class_probabilities for further analysis, such as calculating AUC-ROC\n",
    "# Calculate AUC-ROC\n",
    "auc = roc_auc_score(y_test_combined_rf, positive_class_probabilities)\n",
    "\n",
    "print(f\"Ensemble Model AUC-ROC: {auc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c66bc",
   "metadata": {},
   "source": [
    "<h1>EDA on categorical variables<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3733418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Create a new column 'bmi/age' by dividing 'bmi' by 'age'\n",
    "df_resampled['bmi/age'] = df_resampled['bmi'] / df_resampled['age']\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled, x='age', y='bmi', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Age versus BMI')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('BMI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled, x='blood_glucose_level', y='HbA1c_level', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus HbA1c Level')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('HbA1c Level')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e890597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled, x='age', y='blood_glucose_level', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus HbA1c Level')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Blood Glucose Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled, x='HbA1c_level', y='age', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus HbA1c Level')\n",
    "plt.xlabel('HbA1c Level')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94314722",
   "metadata": {},
   "source": [
    "<h1> Bisecting KMeans <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e6dd11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.692577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321051</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>-1.426157</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.616779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.161089</td>\n",
       "      <td>0.489869</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.261494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.583225</td>\n",
       "      <td>-0.492714</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.514935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.081957</td>\n",
       "      <td>-0.679515</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182959</th>\n",
       "      <td>1.348876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073653</td>\n",
       "      <td>0.932655</td>\n",
       "      <td>0.506959</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182960</th>\n",
       "      <td>1.242402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.496150</td>\n",
       "      <td>0.593863</td>\n",
       "      <td>2.995441</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182961</th>\n",
       "      <td>1.156268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391953</td>\n",
       "      <td>0.615763</td>\n",
       "      <td>0.514433</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182962</th>\n",
       "      <td>0.550334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117714</td>\n",
       "      <td>0.228337</td>\n",
       "      <td>0.136141</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182963</th>\n",
       "      <td>0.624785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.472269</td>\n",
       "      <td>3.184417</td>\n",
       "      <td>1.521575</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182964 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "0       1.692577             0              1 -0.321051     1.001692   \n",
       "1       0.537899             0              0 -0.000114     1.001692   \n",
       "2      -0.616779             0              0 -0.000114     0.161089   \n",
       "3      -0.261494             0              0 -0.583225    -0.492714   \n",
       "4       1.514935             1              1 -1.081957    -0.679515   \n",
       "...          ...           ...            ...       ...          ...   \n",
       "182959  1.348876             0              0  0.073653     0.932655   \n",
       "182960  1.242402             1              0  1.496150     0.593863   \n",
       "182961  1.156268             0              0  0.391953     0.615763   \n",
       "182962  0.550334             0              0  0.117714     0.228337   \n",
       "182963  0.624785             1              0  1.472269     3.184417   \n",
       "\n",
       "        blood_glucose_level  smoking_history_encoded  gender_encoded  diabetes  \n",
       "0                  0.047709                -0.640425       -0.841175         0  \n",
       "1                 -1.426157                -0.640425       -0.841175         0  \n",
       "2                  0.489869                -0.640425        1.188813         0  \n",
       "3                  0.416175                 1.561464       -0.841175         0  \n",
       "4                  0.416175                 1.561464        1.188813         0  \n",
       "...                     ...                      ...             ...       ...  \n",
       "182959             0.506959                -0.640425        1.188813         1  \n",
       "182960             2.995441                -0.640425       -0.841175         1  \n",
       "182961             0.514433                -0.640425       -0.841175         1  \n",
       "182962             0.136141                 1.561464        1.188813         1  \n",
       "182963             1.521575                 1.561464        1.188813         1  \n",
       "\n",
       "[182964 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled_bisect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9227f1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers:\n",
      "[[ 0.87339477  0.27843338  0.1402214   1.23307749  1.97930871  0.45036948\n",
      "   0.60500203  0.19183542]\n",
      " [ 0.87425924  0.22319703  0.13903346  0.61903105  1.19372565  2.82734911\n",
      "   0.30093419  0.11752419]\n",
      " [ 0.40221187  0.12136548  0.07480677  0.12362436  0.04485183 -0.1376749\n",
      "   1.56146424  0.06685256]\n",
      " [-0.01800201  0.07967183  0.04100969 -0.05562417  0.05962994 -0.09115543\n",
      "  -0.64042453 -0.02263625]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.692577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321051</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>-1.426157</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.616779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.161089</td>\n",
       "      <td>0.489869</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.261494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.583225</td>\n",
       "      <td>-0.492714</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.514935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.081957</td>\n",
       "      <td>-0.679515</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182959</th>\n",
       "      <td>1.348876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073653</td>\n",
       "      <td>0.932655</td>\n",
       "      <td>0.506959</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182960</th>\n",
       "      <td>1.242402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.496150</td>\n",
       "      <td>0.593863</td>\n",
       "      <td>2.995441</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182961</th>\n",
       "      <td>1.156268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391953</td>\n",
       "      <td>0.615763</td>\n",
       "      <td>0.514433</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182962</th>\n",
       "      <td>0.550334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117714</td>\n",
       "      <td>0.228337</td>\n",
       "      <td>0.136141</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182963</th>\n",
       "      <td>0.624785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.472269</td>\n",
       "      <td>3.184417</td>\n",
       "      <td>1.521575</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182964 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "0       1.692577             0              1 -0.321051     1.001692   \n",
       "1       0.537899             0              0 -0.000114     1.001692   \n",
       "2      -0.616779             0              0 -0.000114     0.161089   \n",
       "3      -0.261494             0              0 -0.583225    -0.492714   \n",
       "4       1.514935             1              1 -1.081957    -0.679515   \n",
       "...          ...           ...            ...       ...          ...   \n",
       "182959  1.348876             0              0  0.073653     0.932655   \n",
       "182960  1.242402             1              0  1.496150     0.593863   \n",
       "182961  1.156268             0              0  0.391953     0.615763   \n",
       "182962  0.550334             0              0  0.117714     0.228337   \n",
       "182963  0.624785             1              0  1.472269     3.184417   \n",
       "\n",
       "        blood_glucose_level  smoking_history_encoded  gender_encoded  clusters  \n",
       "0                  0.047709                -0.640425       -0.841175         4  \n",
       "1                 -1.426157                -0.640425       -0.841175         4  \n",
       "2                  0.489869                -0.640425        1.188813         4  \n",
       "3                  0.416175                 1.561464       -0.841175         3  \n",
       "4                  0.416175                 1.561464        1.188813         3  \n",
       "...                     ...                      ...             ...       ...  \n",
       "182959             0.506959                -0.640425        1.188813         4  \n",
       "182960             2.995441                -0.640425       -0.841175         2  \n",
       "182961             0.514433                -0.640425       -0.841175         4  \n",
       "182962             0.136141                 1.561464        1.188813         3  \n",
       "182963             1.521575                 1.561464        1.188813         1  \n",
       "\n",
       "[182964 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bisect = df_resampled_bisect.iloc[:, 0:8]\n",
    "y_bisect = df_resampled_bisect.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Instantiate BisectingKMeans with desired number of clusters\n",
    "bkm = BisectingKMeans(n_clusters=4, random_state=424)\n",
    "\n",
    "# Fit the model to the data\n",
    "bkm.fit(X_bisect)\n",
    "\n",
    "\n",
    "\n",
    "# Predict the clusters for the data points\n",
    "labels = bkm.predict(X_bisect) + 1\n",
    "\n",
    "# Print the cluster centers\n",
    "print(\"Cluster centers:\")\n",
    "print(bkm.cluster_centers_)\n",
    "\n",
    "X_bisect['clusters']=labels\n",
    "X_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "307e59e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.692577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.321051</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>0.047709</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.537899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.001692</td>\n",
       "      <td>-1.426157</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.616779</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.161089</td>\n",
       "      <td>0.489869</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.261494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.583225</td>\n",
       "      <td>-0.492714</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.514935</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.081957</td>\n",
       "      <td>-0.679515</td>\n",
       "      <td>0.416175</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182959</th>\n",
       "      <td>1.348876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073653</td>\n",
       "      <td>0.932655</td>\n",
       "      <td>0.506959</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182960</th>\n",
       "      <td>1.242402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.496150</td>\n",
       "      <td>0.593863</td>\n",
       "      <td>2.995441</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182961</th>\n",
       "      <td>1.156268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391953</td>\n",
       "      <td>0.615763</td>\n",
       "      <td>0.514433</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182962</th>\n",
       "      <td>0.550334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117714</td>\n",
       "      <td>0.228337</td>\n",
       "      <td>0.136141</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182963</th>\n",
       "      <td>0.624785</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.472269</td>\n",
       "      <td>3.184417</td>\n",
       "      <td>1.521575</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182964 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "0       1.692577             0              1 -0.321051     1.001692   \n",
       "1       0.537899             0              0 -0.000114     1.001692   \n",
       "2      -0.616779             0              0 -0.000114     0.161089   \n",
       "3      -0.261494             0              0 -0.583225    -0.492714   \n",
       "4       1.514935             1              1 -1.081957    -0.679515   \n",
       "...          ...           ...            ...       ...          ...   \n",
       "182959  1.348876             0              0  0.073653     0.932655   \n",
       "182960  1.242402             1              0  1.496150     0.593863   \n",
       "182961  1.156268             0              0  0.391953     0.615763   \n",
       "182962  0.550334             0              0  0.117714     0.228337   \n",
       "182963  0.624785             1              0  1.472269     3.184417   \n",
       "\n",
       "        blood_glucose_level  smoking_history_encoded  gender_encoded  \\\n",
       "0                  0.047709                -0.640425       -0.841175   \n",
       "1                 -1.426157                -0.640425       -0.841175   \n",
       "2                  0.489869                -0.640425        1.188813   \n",
       "3                  0.416175                 1.561464       -0.841175   \n",
       "4                  0.416175                 1.561464        1.188813   \n",
       "...                     ...                      ...             ...   \n",
       "182959             0.506959                -0.640425        1.188813   \n",
       "182960             2.995441                -0.640425       -0.841175   \n",
       "182961             0.514433                -0.640425       -0.841175   \n",
       "182962             0.136141                 1.561464        1.188813   \n",
       "182963             1.521575                 1.561464        1.188813   \n",
       "\n",
       "        diabetes  clusters  \n",
       "0              0         4  \n",
       "1              0         4  \n",
       "2              0         4  \n",
       "3              0         3  \n",
       "4              0         3  \n",
       "...          ...       ...  \n",
       "182959         1         4  \n",
       "182960         1         2  \n",
       "182961         1         4  \n",
       "182962         1         3  \n",
       "182963         1         1  \n",
       "\n",
       "[182964 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the 'clusters' column to the original DataFrame\n",
    "df_resampled_bisect['clusters'] = X_bisect['clusters']\n",
    "\n",
    "# Display the DataFrame with added 'clusters' column\n",
    "df_resampled_bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3868fe23",
   "metadata": {},
   "source": [
    "<h1> Logistic Prediction on bisect Cluster groups <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "156de84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over unique cluster values\n",
    "for cluster_value in df_resampled_bisect['clusters'].unique():\n",
    "    # Create a DataFrame for the current cluster\n",
    "    cluster_idx_bisect = df_resampled_bisect[df_resampled_bisect['clusters'] == cluster_value].copy()\n",
    "    \n",
    "    # Create a variable for the current DataFrame\n",
    "    globals()[f'cluster_{cluster_value}_bisect'] = cluster_idx_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ca50748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.115238</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.908292</td>\n",
       "      <td>1.521575</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.360256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>0.161089</td>\n",
       "      <td>2.995441</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.759953</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.634454</td>\n",
       "      <td>0.908292</td>\n",
       "      <td>1.521575</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.261494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.745725</td>\n",
       "      <td>0.628091</td>\n",
       "      <td>2.012863</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.804363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>1.842295</td>\n",
       "      <td>3.978018</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182942</th>\n",
       "      <td>-0.028645</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.861382</td>\n",
       "      <td>3.041365</td>\n",
       "      <td>3.964749</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182947</th>\n",
       "      <td>-0.647437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.912364</td>\n",
       "      <td>0.650385</td>\n",
       "      <td>3.978018</td>\n",
       "      <td>1.561464</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182955</th>\n",
       "      <td>0.506408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.598392</td>\n",
       "      <td>0.677823</td>\n",
       "      <td>1.862287</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182958</th>\n",
       "      <td>1.692577</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>3.243301</td>\n",
       "      <td>2.494119</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>1.188813</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182960</th>\n",
       "      <td>1.242402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.496150</td>\n",
       "      <td>0.593863</td>\n",
       "      <td>2.995441</td>\n",
       "      <td>-0.640425</td>\n",
       "      <td>-0.841175</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40405 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  hypertension  heart_disease       bmi  HbA1c_level  \\\n",
       "26      1.115238             0              1 -0.000114     0.908292   \n",
       "38      0.360256             1              0 -0.000114     0.161089   \n",
       "65      0.759953             0              1 -0.634454     0.908292   \n",
       "87     -0.261494             0              0  0.745725     0.628091   \n",
       "94      0.804363             0              0 -0.000114     1.842295   \n",
       "...          ...           ...            ...       ...          ...   \n",
       "182942 -0.028645             1              0  0.861382     3.041365   \n",
       "182947 -0.647437             0              0  1.912364     0.650385   \n",
       "182955  0.506408             0              0  2.598392     0.677823   \n",
       "182958  1.692577             1              0  0.000194     3.243301   \n",
       "182960  1.242402             1              0  1.496150     0.593863   \n",
       "\n",
       "        blood_glucose_level  smoking_history_encoded  gender_encoded  \\\n",
       "26                 1.521575                 1.561464        1.188813   \n",
       "38                 2.995441                 1.561464        1.188813   \n",
       "65                 1.521575                 1.561464       -0.841175   \n",
       "87                 2.012863                 1.561464       -0.841175   \n",
       "94                 3.978018                -0.640425       -0.841175   \n",
       "...                     ...                      ...             ...   \n",
       "182942             3.964749                -0.640425        1.188813   \n",
       "182947             3.978018                 1.561464       -0.841175   \n",
       "182955             1.862287                -0.640425        1.188813   \n",
       "182958             2.494119                -0.640425        1.188813   \n",
       "182960             2.995441                -0.640425       -0.841175   \n",
       "\n",
       "        diabetes  clusters  \n",
       "26             1         2  \n",
       "38             1         2  \n",
       "65             0         2  \n",
       "87             1         2  \n",
       "94             1         2  \n",
       "...          ...       ...  \n",
       "182942         1         2  \n",
       "182947         1         2  \n",
       "182955         1         2  \n",
       "182958         1         2  \n",
       "182960         1         2  \n",
       "\n",
       "[40405 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_2_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bf96e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9356924954240391\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.10      0.17       546\n",
      "           1       0.94      1.00      0.97      7649\n",
      "\n",
      "    accuracy                           0.94      8195\n",
      "   macro avg       0.77      0.55      0.57      8195\n",
      "weighted avg       0.92      0.94      0.91      8195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_cluster_1_bisect = cluster_1_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_1_bisect = X_cluster_1_bisect.drop('clusters', axis = 1)\n",
    "y_cluster_1_bisect = cluster_1_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_1_bisect, X_test_cluster_1_bisect, y_train_cluster_1_bisect, y_test_cluster_1_bisect = train_test_split(X_cluster_1_bisect, y_cluster_1_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_1_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_1_bisect.fit(X_train_cluster_1_bisect, y_train_cluster_1_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_1_bisect = logreg_1_bisect.predict(X_test_cluster_1_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_1_bisect, predictions_1_bisect)\n",
    "classification_rep = classification_report(y_test_cluster_1_bisect, predictions_1_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "813074f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9638673486223396\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.51      0.59       617\n",
      "           1       0.97      0.99      0.98     11505\n",
      "\n",
      "    accuracy                           0.96     12122\n",
      "   macro avg       0.84      0.75      0.78     12122\n",
      "weighted avg       0.96      0.96      0.96     12122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_cluster_2_bisect = cluster_2_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_2_bisect = X_cluster_2_bisect.drop('clusters', axis = 1)\n",
    "y_cluster_2_bisect = cluster_2_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_2_bisect, X_test_cluster_2_bisect, y_train_cluster_2_bisect, y_test_cluster_2_bisect = train_test_split(X_cluster_2_bisect, y_cluster_2_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_2_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_2_bisect.fit(X_train_cluster_2_bisect, y_train_cluster_2_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_2_bisect = logreg_2_bisect.predict(X_test_cluster_2_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_2_bisect, predictions_2_bisect)\n",
    "classification_rep = classification_report(y_test_cluster_2_bisect, predictions_2_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77471d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8253935800449805\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      6967\n",
      "           1       0.71      0.67      0.69      2815\n",
      "\n",
      "    accuracy                           0.83      9782\n",
      "   macro avg       0.79      0.78      0.78      9782\n",
      "weighted avg       0.82      0.83      0.82      9782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_cluster_3_bisect = cluster_3_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_3_bisect = X_cluster_3_bisect.drop('clusters', axis = 1)\n",
    "y_cluster_3_bisect = cluster_3_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_3_bisect, X_test_cluster_3_bisect, y_train_cluster_3_bisect, y_test_cluster_3_bisect = train_test_split(X_cluster_3_bisect, y_cluster_3_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_3_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_3_bisect.fit(X_train_cluster_3_bisect, y_train_cluster_3_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_3_bisect = logreg_3_bisect.predict(X_test_cluster_3_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_3_bisect, predictions_3_bisect)\n",
    "classification_rep = classification_report(y_test_cluster_3_bisect, predictions_3_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cec0c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8600354953210713\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91     19310\n",
      "           1       0.71      0.62      0.66      5482\n",
      "\n",
      "    accuracy                           0.86     24792\n",
      "   macro avg       0.80      0.77      0.79     24792\n",
      "weighted avg       0.85      0.86      0.86     24792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_cluster_4_bisect = cluster_4_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_4_bisect = X_cluster_4_bisect.drop('clusters', axis = 1)\n",
    "y_cluster_4_bisect = cluster_4_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_4_bisect, X_test_cluster_4_bisect, y_train_cluster_4_bisect, y_test_cluster_4_bisect = train_test_split(X_cluster_4_bisect, y_cluster_4_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_4_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_4_bisect.fit(X_train_cluster_4_bisect, y_train_cluster_4_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_4_bisect = logreg_4_bisect.predict(X_test_cluster_4_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_4_bisect, predictions_4_bisect)\n",
    "classification_rep = classification_report(y_test_cluster_4_bisect, predictions_4_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0738b84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Bisect Model Accuracy: 0.5205684095463654\n",
      "Ensemble Bisect Model Precision: 0.8834241587296592\n",
      "Ensemble Bisect Model Recall: 0.8834213882310075\n",
      "Ensemble Bisect Model F1-score: 0.883421124150548\n",
      "Ensemble Bisect Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88     27453\n",
      "           1       0.88      0.88      0.88     27437\n",
      "\n",
      "    accuracy                           0.88     54890\n",
      "   macro avg       0.88      0.88      0.88     54890\n",
      "weighted avg       0.88      0.88      0.88     54890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Combine features and labels from all clusters\n",
    "X_bisect_combined = np.concatenate((X_cluster_1_bisect, X_cluster_3_bisect, X_cluster_2_bisect, X_cluster_4_bisect), axis=0)\n",
    "y_bisect_combined = np.concatenate((y_cluster_1_bisect, y_cluster_3_bisect, y_cluster_2_bisect, y_cluster_4_bisect), axis=0)\n",
    "\n",
    "# Split the bisect_combined data into training and test sets\n",
    "X_train_bisect_combined, X_test_bisect_combined, y_train_bisect_combined, y_test_bisect_combined = train_test_split(X_bisect_combined, y_bisect_combined, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1_bisect', logreg_1_bisect), ('cluster_2_bisect', logreg_2_bisect), ('cluster_3_bisect', logreg_3_bisect), ('cluster_4_bisect', logreg_4_bisect)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the bisect_combined training set\n",
    "voting_clf.fit(X_train_bisect_combined, y_train_bisect_combined)\n",
    "\n",
    "# Make predictions using the ensemble model on the bisect_combined test set\n",
    "ensemble_predictions_bisect = voting_clf.predict(X_test_bisect_combined)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble_bisect = accuracy_score(y_test_bisect_combined, ensemble_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision_ensemble_bisect = precision_score(y_test_bisect_combined, ensemble_predictions_bisect, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_ensemble_bisect = recall_score(y_test_bisect_combined, ensemble_predictions_bisect, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_ensemble_bisect = f1_score(y_test_bisect_combined, ensemble_predictions_bisect, average='weighted')\n",
    "\n",
    "classification_report_ensemble_bisect = classification_report(y_test_bisect_combined, ensemble_predictions_bisect)\n",
    "\n",
    "print(f\"Ensemble Bisect Model Accuracy: {accuracy_ensemble_bisect}\")\n",
    "print(f\"Ensemble Bisect Model Precision: {precision_ensemble_bisect}\")\n",
    "print(f\"Ensemble Bisect Model Recall: {recall_ensemble_bisect}\")\n",
    "print(f\"Ensemble Bisect Model F1-score: {f1_ensemble_bisect}\")\n",
    "\n",
    "\n",
    "print(\"Ensemble Bisect Model Classification Report:\")\n",
    "print(classification_report_ensemble_bisect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c36587f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model AUC-ROC: 0.9621730326338748\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Fit the VotingClassifier on the combined_rf training set\n",
    "voting_clf.fit(X_train_bisect_combined, y_train_bisect_combined)\n",
    "\n",
    "# Initialize an empty array to store the predicted probabilities\n",
    "ensemble_probabilities = np.zeros((len(X_test_bisect_combined), 2))  # Assuming binary classification\n",
    "\n",
    "# Iterate over individual models in the ensemble\n",
    "for estimator in voting_clf.estimators_:\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    class_probabilities = estimator.predict_proba(X_test_bisect_combined)\n",
    "    # Aggregate the predicted probabilities\n",
    "    ensemble_probabilities += class_probabilities\n",
    "\n",
    "# Take the average of the predicted probabilities\n",
    "ensemble_probabilities /= len(voting_clf.estimators_)\n",
    "\n",
    "# Extract the probabilities for the positive class (assuming binary classification)\n",
    "positive_class_probabilities = ensemble_probabilities[:, 1]\n",
    "\n",
    "# Now you can use positive_class_probabilities for further analysis, such as calculating AUC-ROC\n",
    "# Calculate AUC-ROC\n",
    "auc = roc_auc_score(y_test_bisect_combined, positive_class_probabilities)\n",
    "\n",
    "print(f\"Ensemble Model AUC-ROC: {auc}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f05ff",
   "metadata": {},
   "source": [
    "<h1>Random Forests model on bisect clusters<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f84ece69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model 1 Bisect Accuracy: 0.975960951799878\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80       546\n",
      "           1       0.98      1.00      0.99      7649\n",
      "\n",
      "    accuracy                           0.98      8195\n",
      "   macro avg       0.95      0.85      0.89      8195\n",
      "weighted avg       0.97      0.98      0.97      8195\n",
      "\n",
      "Cross-validated Biscet Accuracy Scores: [0.97071895 0.97751046 0.97358787 0.97437238 0.97306485]\n",
      "Mean Cross-validated Bisect Accuracy: 0.9738509038203844\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_cluster_1_bisect, X_test_cluster_1_bisect, y_train_cluster_1_bisect, y_test_cluster_1_bisect = train_test_split(X_cluster_1_bisect, y_cluster_1_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "\n",
    "# Create and train the first Random Forest model\n",
    "rf_model1_bisect = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model1_bisect.fit(X_train_cluster_1_bisect, y_train_cluster_1_bisect)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf1_bisect = rf_model1_bisect.predict(X_test_cluster_1_bisect)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf1_bisect = accuracy_score(y_test_cluster_1_bisect, y_pred_rf1_bisect)\n",
    "print(\"Random Forest Model 1 Bisect Accuracy:\", accuracy_rf1_bisect)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_1_bisect, y_pred_rf1_bisect)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model1_bisect, X_train_cluster_1_bisect, y_train_cluster_1_bisect, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Biscet Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Bisect Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "995987c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model 2 Bisect Accuracy: 0.9891932024418413\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       617\n",
      "           1       0.99      1.00      0.99     11505\n",
      "\n",
      "    accuracy                           0.99     12122\n",
      "   macro avg       0.96      0.93      0.94     12122\n",
      "weighted avg       0.99      0.99      0.99     12122\n",
      "\n",
      "Cross-validated Biscet Accuracy Scores: [0.98515114 0.98656532 0.98815627 0.98391089 0.98673975]\n",
      "Mean Cross-validated Bisect Accuracy: 0.9861046721101818\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_cluster_2_bisect, X_test_cluster_2_bisect, y_train_cluster_2_bisect, y_test_cluster_2_bisect = train_test_split(X_cluster_2_bisect, y_cluster_2_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "\n",
    "# Create and train the first Random Forest model\n",
    "rf_model2_bisect = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model2_bisect.fit(X_train_cluster_2_bisect, y_train_cluster_2_bisect)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf2_bisect = rf_model2_bisect.predict(X_test_cluster_2_bisect)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf2_bisect = accuracy_score(y_test_cluster_2_bisect, y_pred_rf2_bisect)\n",
    "print(\"Random Forest Model 2 Bisect Accuracy:\", accuracy_rf2_bisect)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_2_bisect, y_pred_rf2_bisect)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model2_bisect, X_train_cluster_2_bisect, y_train_cluster_2_bisect, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Biscet Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Bisect Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da33d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model 3 Bisect Accuracy: 0.9676957677366592\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      6967\n",
      "           1       0.94      0.95      0.94      2815\n",
      "\n",
      "    accuracy                           0.97      9782\n",
      "   macro avg       0.96      0.96      0.96      9782\n",
      "weighted avg       0.97      0.97      0.97      9782\n",
      "\n",
      "Cross-validated Biscet Accuracy Scores: [0.95991238 0.96560789 0.95880806 0.95354952 0.96056091]\n",
      "Mean Cross-validated Bisect Accuracy: 0.9596877510840109\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_cluster_3_bisect, X_test_cluster_3_bisect, y_train_cluster_3_bisect, y_test_cluster_3_bisect = train_test_split(X_cluster_3_bisect, y_cluster_3_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "\n",
    "# Create and train the first Random Forest model\n",
    "rf_model3_bisect = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model3_bisect.fit(X_train_cluster_3_bisect, y_train_cluster_3_bisect)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf3_bisect = rf_model3_bisect.predict(X_test_cluster_3_bisect)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf3_bisect = accuracy_score(y_test_cluster_3_bisect, y_pred_rf3_bisect)\n",
    "print(\"Random Forest Model 3 Bisect Accuracy:\", accuracy_rf3_bisect)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_3_bisect, y_pred_rf3_bisect)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model3_bisect, X_train_cluster_3_bisect, y_train_cluster_3_bisect, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Biscet Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Bisect Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d92172db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model 4 Bisect Accuracy: 0.9720070990642142\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     19310\n",
      "           1       0.94      0.93      0.94      5482\n",
      "\n",
      "    accuracy                           0.97     24792\n",
      "   macro avg       0.96      0.96      0.96     24792\n",
      "weighted avg       0.97      0.97      0.97     24792\n",
      "\n",
      "Cross-validated Biscet Accuracy Scores: [0.96853933 0.9693172  0.97320425 0.97199412 0.97121618]\n",
      "Mean Cross-validated Bisect Accuracy: 0.9708542163276774\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_cluster_4_bisect, X_test_cluster_4_bisect, y_train_cluster_4_bisect, y_test_cluster_4_bisect = train_test_split(X_cluster_4_bisect, y_cluster_4_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "\n",
    "# Create and train the first Random Forest model\n",
    "rf_model4_bisect = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model4_bisect.fit(X_train_cluster_4_bisect, y_train_cluster_4_bisect)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf4_bisect = rf_model4_bisect.predict(X_test_cluster_4_bisect)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf4_bisect = accuracy_score(y_test_cluster_4_bisect, y_pred_rf4_bisect)\n",
    "print(\"Random Forest Model 4 Bisect Accuracy:\", accuracy_rf4_bisect)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_4_bisect, y_pred_rf4_bisect)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model4_bisect, X_train_cluster_4_bisect, y_train_cluster_4_bisect, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Biscet Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Bisect Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2b626e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model Accuracy: 0.9757150664966296\n",
      "Ensemble Model Precision: 0.9757188030968611\n",
      "Ensemble Model Recall: 0.9757150664966296\n",
      "Ensemble Model F1-score: 0.9757148099003887\n",
      "Ensemble Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98     27289\n",
      "           1       0.97      0.98      0.98     27601\n",
      "\n",
      "    accuracy                           0.98     54890\n",
      "   macro avg       0.98      0.98      0.98     54890\n",
      "weighted avg       0.98      0.98      0.98     54890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine features and labels from all clusters\n",
    "X_bisect_combined_rf = np.concatenate((X_cluster_1_bisect, X_cluster_2_bisect, X_cluster_3_bisect, X_cluster_4_bisect), axis=0)\n",
    "y_bisect_combined_rf = np.concatenate((y_cluster_1_bisect, y_cluster_2_bisect, y_cluster_3_bisect, y_cluster_4_bisect), axis=0)\n",
    "\n",
    "# Split the combined_rf data into training and test sets\n",
    "X_train_combined_rf_bisect, X_test_combined_rf_bisect, y_train_combined_rf_bisect, y_test_combined_rf_bisect = train_test_split(X_bisect_combined_rf, y_bisect_combined_rf, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1_bisect', rf_model1_bisect), ('cluster_2_bisect', rf_model2_bisect), ('cluster_3_bisect', rf_model3_bisect), ('cluster_4_bisect', rf_model4_bisect)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the combined_rf training set\n",
    "voting_clf.fit(X_train_combined_rf_bisect, y_train_combined_rf_bisect)\n",
    "\n",
    "# Make predictions using the ensemble model on the combined_rf test set\n",
    "ensemble_predictions = voting_clf.predict(X_test_combined_rf_bisect)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y_test_combined_rf_bisect, ensemble_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision_ensemble = precision_score(y_test_combined_rf_bisect, ensemble_predictions, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_ensemble = recall_score(y_test_combined_rf_bisect, ensemble_predictions, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_ensemble = f1_score(y_test_combined_rf_bisect, ensemble_predictions, average='weighted')\n",
    "\n",
    "classification_report_ensemble = classification_report(y_test_combined_rf_bisect, ensemble_predictions)\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble}\")\n",
    "print(f\"Ensemble Model Precision: {precision_ensemble}\")\n",
    "print(f\"Ensemble Model Recall: {recall_ensemble}\")\n",
    "print(f\"Ensemble Model F1-score: {f1_ensemble}\")\n",
    "\n",
    "\n",
    "print(\"Ensemble Model Classification Report:\")\n",
    "print(classification_report_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee5fe944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model AUC-ROC: 0.9975736005722086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Fit the VotingClassifier on the combined_rf training set\n",
    "voting_clf.fit(X_train_combined_rf_bisect, y_train_combined_rf_bisect)\n",
    "\n",
    "# Initialize an empty array to store the predicted probabilities\n",
    "ensemble_probabilities = np.zeros((len(X_test_combined_rf_bisect), 2))  # Assuming binary classification\n",
    "\n",
    "# Iterate over individual models in the ensemble\n",
    "for estimator in voting_clf.estimators_:\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    class_probabilities = estimator.predict_proba(X_test_combined_rf_bisect)\n",
    "    # Aggregate the predicted probabilities\n",
    "    ensemble_probabilities += class_probabilities\n",
    "\n",
    "# Take the average of the predicted probabilities\n",
    "ensemble_probabilities /= len(voting_clf.estimators_)\n",
    "\n",
    "# Extract the probabilities for the positive class (assuming binary classification)\n",
    "positive_class_probabilities = ensemble_probabilities[:, 1]\n",
    "\n",
    "# Now you can use positive_class_probabilities for further analysis, such as calculating AUC-ROC\n",
    "# Calculate AUC-ROC\n",
    "auc = roc_auc_score(y_test_combined_rf_bisect, positive_class_probabilities)\n",
    "\n",
    "print(f\"Ensemble Model AUC-ROC: {auc}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84828f8e",
   "metadata": {},
   "source": [
    "<h1>EDA on categorical variables bisect df<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled_bisect, x='age', y='bmi', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Age versus BMI')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('BMI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64163f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled_bisect, x='blood_glucose_level', y='HbA1c_level', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus HbA1c Level')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('HbA1c Level')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9051867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled_bisect, x='blood_glucose_level', y='age', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus Age')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a2986",
   "metadata": {},
   "source": [
    "<h1> Features Importance Incorporated <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4262e8c",
   "metadata": {},
   "source": [
    "<h1>K-Means Important Clustering <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"hypertension\", \"heart_disease\", \"smoking_history_encoded\", \"gender_encoded\"]\n",
    "df_resesampled_imp = df_resampled.copy()\n",
    "df_resampled_imp = df_resampled_imp.drop(columns=columns_to_drop)\n",
    "df_important_bisect = df_resampled_imp.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ffe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important = df_resampled_imp.iloc[:, 0:4]\n",
    "y = df_resampled_imp.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e821199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit KMeans model\n",
    "model=KMeans(n_clusters=4, n_init=10, random_state=424)\n",
    "model.fit(X_important)\n",
    "\n",
    "labels=model.labels_ + 1\n",
    "labels  #clustering into 2 groups: 0 and 1\n",
    "\n",
    "centers=model.cluster_centers_\n",
    "centers\n",
    "\n",
    "model.inertia_\n",
    "\n",
    "X_important['clusters']=labels\n",
    "X_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3d20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia_train={}\n",
    "for n_cluster in range(1,10):\n",
    "    model=KMeans(n_clusters=n_cluster, n_init=10, random_state =424)\n",
    "    model.fit(X_important)\n",
    "    inertia_train[n_cluster]=model.inertia_\n",
    "    \n",
    "plt.plot(range(1,10),inertia_train.values())\n",
    "plt.xlabel('The number of clusters with important') #inertia is the measure of each dots to its centers: tight clusters, low inertia\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee81354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the 'clusters' column to the original DataFrame\n",
    "df_resampled_imp['clusters'] = X_important['clusters']\n",
    "\n",
    "# Display the DataFrame with added 'clusters' column\n",
    "df_resampled_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_1 = df_resampled_imp[df_resampled_imp[\"clusters\"] == 1]\n",
    "important_2 = df_resampled_imp[df_resampled_imp[\"clusters\"] == 2]\n",
    "important_3 = df_resampled_imp[df_resampled_imp[\"clusters\"] == 3]\n",
    "important_4 = df_resampled_imp[df_resampled_imp[\"clusters\"] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e2aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_1 = important_1.drop('diabetes', axis=1)  # Features\n",
    "X_important_1 = X_important_1.drop('clusters', axis = 1)\n",
    "y_important_1 = important_1['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_important_1, X_test_important_1, y_train_important_1, y_test_important_1 = train_test_split(X_important_1, y_important_1, test_size=0.1, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_1 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_1.fit(X_train_important_1, y_train_important_1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_1 = logreg_1.predict(X_test_important_1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_important_1, predictions_1)\n",
    "classification_rep = classification_report(y_test_important_1, predictions_1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_2 = important_2.drop('diabetes', axis=1)  # Features\n",
    "X_important_2 = X_important_2.drop('clusters', axis = 1)\n",
    "y_important_2 = important_2['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_important_2, X_test_important_2, y_train_important_2, y_test_important_2 = train_test_split(X_important_2, y_important_2, test_size=0.1, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_2 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_2.fit(X_train_important_2, y_train_important_2)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_2 = logreg_2.predict(X_test_important_2)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_important_2, predictions_2)\n",
    "classification_rep = classification_report(y_test_important_2, predictions_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_3 = important_3.drop('diabetes', axis=1)  # Features\n",
    "X_important_3 = X_important_3.drop('clusters', axis = 1)\n",
    "y_important_3 = important_3['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_important_3, X_test_important_3, y_train_important_3, y_test_important_3 = train_test_split(X_important_3, y_important_3, test_size=0.1, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_3 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_3.fit(X_train_important_3, y_train_important_3)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_3 = logreg_3.predict(X_test_important_3)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_important_3, predictions_3)\n",
    "classification_rep = classification_report(y_test_important_3, predictions_3)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d421c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_4 = important_4.drop('diabetes', axis=1)  # Features\n",
    "X_important_4 = X_important_4.drop('clusters', axis = 1)\n",
    "y_important_4 = important_4['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_important_4, X_test_important_4, y_train_important_4, y_test_important_4 = train_test_split(X_important_4, y_important_4, test_size=0.1, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_4 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_4.fit(X_train_important_4, y_train_important_4)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_4 = logreg_4.predict(X_test_important_4)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_important_4, predictions_4)\n",
    "classification_rep = classification_report(y_test_important_4, predictions_4)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c4ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Combine features and labels from all importants\n",
    "X_combined_important = np.concatenate((X_important_1, X_important_3, X_important_2, X_important_4), axis=0)\n",
    "y_combined_important = np.concatenate((y_important_1, y_important_3, y_important_2, y_important_4), axis=0)\n",
    "\n",
    "# Split the combined_important data into training and test sets\n",
    "X_train_combined_important, X_test_combined_important, y_train_combined_important, y_test_combined_important = train_test_split(X_combined_important, y_combined_important, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('important_1', logreg_1), ('important_3', logreg_3), ('important_2', logreg_2), ('important_4', logreg_4)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the combined_important training set\n",
    "voting_clf.fit(X_train_combined_important, y_train_combined_important)\n",
    "\n",
    "# Make predictions using the ensemble model on the combined_important test set\n",
    "ensemble_predictions = voting_clf.predict(X_test_combined_important)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y_test_combined_important, ensemble_predictions)\n",
    "# Calculate precision\n",
    "precision_ensemble = precision_score(y_test_combined_important, ensemble_predictions, average='weighted')\n",
    "# Calculate recall\n",
    "recall_ensemble = recall_score(y_test_combined_important, ensemble_predictions, average='weighted')\n",
    "# Calculate F1-score\n",
    "f1_ensemble = f1_score(y_test_combined_important, ensemble_predictions, average='weighted')\n",
    "# Calculate the AUC score\n",
    "auc_ensemble = roc_auc_score(y_test_combined_important, ensemble_predictions)\n",
    "\n",
    "\n",
    "classification_report_ensemble = classification_report(y_test_combined_important, ensemble_predictions)\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble}\")\n",
    "print(f\"Ensemble Model Precision: {precision_ensemble}\")\n",
    "print(f\"Ensemble Model Recall: {recall_ensemble}\")\n",
    "print(f\"Ensemble Model f1: {f1_ensemble}\")\n",
    "print(f\"Ensemble Model AUC ROC: {auc_ensemble}\")\n",
    "print(\"Ensemble Model Classification Report:\")\n",
    "print(classification_report_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1659f705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled_imp, x='age', y='bmi', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Age versus BMI')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('BMI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71954125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled_imp, x='blood_glucose_level', y='HbA1c_level', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus HbA1c Level')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('HbA1c Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled_imp, x='blood_glucose_level', y='age', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus Age')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fdfbdc",
   "metadata": {},
   "source": [
    "<h1>Bisect K-Means Important Clustering <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566edab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_bisect = df_important_bisect.iloc[:, 0:4]\n",
    "y_bisect = df_important_bisect.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Instantiate BisectingKMeans with desired number of clusters\n",
    "bkm = BisectingKMeans(n_clusters=4, random_state=424)\n",
    "\n",
    "# Fit the model to the data\n",
    "bkm.fit(X_important_bisect)\n",
    "\n",
    "\n",
    "\n",
    "# Predict the clusters for the data points\n",
    "labels = bkm.predict(X_important_bisect) + 1\n",
    "\n",
    "# Print the cluster centers\n",
    "print(\"Cluster centers:\")\n",
    "print(bkm.cluster_centers_)\n",
    "\n",
    "X_important_bisect['clusters']=labels\n",
    "X_important_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5c514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the 'clusters' column to the original DataFrame\n",
    "df_important_bisect['clusters'] = X_important_bisect['clusters']\n",
    "\n",
    "# Display the DataFrame with added 'clusters' column\n",
    "df_important_bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a8b41",
   "metadata": {},
   "source": [
    "<h1> Logistic Prediction on important bisect Cluster groups <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over unique cluster values\n",
    "for cluster_value in df_important_bisect['clusters'].unique():\n",
    "    # Create a DataFrame for the current cluster\n",
    "    cluster_idx_important_bisect = df_important_bisect[df_important_bisect['clusters'] == cluster_value].copy()\n",
    "    \n",
    "    # Create a variable for the current DataFrame\n",
    "    globals()[f'cluster_{cluster_value}_important_bisect'] = cluster_idx_important_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db4ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_important_bisect = cluster_1_important_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_1_important_bisect = X_1_important_bisect.drop('clusters', axis = 1)\n",
    "y_1_important_bisect = cluster_1_important_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_1_important_bisect, X_test_1_important_bisect, y_train_1_important_bisect, y_test_1_important_bisect = train_test_split(X_1_important_bisect, y_1_important_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_1_important_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_1_important_bisect.fit(X_train_1_important_bisect, y_train_1_important_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_1_important_bisect = logreg_1_important_bisect.predict(X_test_1_important_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_1_important_bisect, predictions_1_important_bisect)\n",
    "classification_rep = classification_report(y_test_1_important_bisect, predictions_1_important_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3_important_bisect = cluster_3_important_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_3_important_bisect = X_3_important_bisect.drop('clusters', axis = 1)\n",
    "y_3_important_bisect = cluster_3_important_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_3_important_bisect, X_test_3_important_bisect, y_train_3_important_bisect, y_test_3_important_bisect = train_test_split(X_3_important_bisect, y_3_important_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_3_important_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_3_important_bisect.fit(X_train_3_important_bisect, y_train_3_important_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_3_important_bisect = logreg_3_important_bisect.predict(X_test_3_important_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_3_important_bisect, predictions_3_important_bisect)\n",
    "classification_rep = classification_report(y_test_3_important_bisect, predictions_3_important_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4_important_bisect = cluster_4_important_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_4_important_bisect = X_4_important_bisect.drop('clusters', axis = 1)\n",
    "y_4_important_bisect = cluster_4_important_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_4_important_bisect, X_test_4_important_bisect, y_train_4_important_bisect, y_test_4_important_bisect = train_test_split(X_4_important_bisect, y_4_important_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_4_important_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_4_important_bisect.fit(X_train_4_important_bisect, y_train_4_important_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_4_important_bisect = logreg_4_important_bisect.predict(X_test_4_important_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_4_important_bisect, predictions_4_important_bisect)\n",
    "classification_rep = classification_report(y_test_4_important_bisect, predictions_4_important_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2_important_bisect = cluster_2_important_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_2_important_bisect = X_2_important_bisect.drop('clusters', axis = 1)\n",
    "y_2_important_bisect = cluster_2_important_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_2_important_bisect, X_test_2_important_bisect, y_train_2_important_bisect, y_test_2_important_bisect = train_test_split(X_2_important_bisect, y_2_important_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_2_important_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_2_important_bisect.fit(X_train_2_important_bisect, y_train_2_important_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_2_important_bisect = logreg_2_important_bisect.predict(X_test_2_important_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_2_important_bisect, predictions_2_important_bisect)\n",
    "classification_rep = classification_report(y_test_2_important_bisect, predictions_2_important_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Combine features and labels from all clusters\n",
    "X_important_bisect_combined = np.concatenate((X_1_important_bisect, X_3_important_bisect, X_2_important_bisect, X_4_important_bisect), axis=0)\n",
    "y_important_bisect_combined = np.concatenate((y_1_important_bisect, y_3_important_bisect, y_2_important_bisect, y_4_important_bisect), axis=0)\n",
    "\n",
    "# Split the bisect_combined data into training and test sets\n",
    "X_train_important_bisect_combined, X_test_important_bisect_combined, y_train_important_bisect_combined, y_test_important_bisect_combined = train_test_split(X_important_bisect_combined, y_important_bisect_combined, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1_important_bisect', logreg_1_important_bisect), ('cluster_2_important_bisect', logreg_2_important_bisect), ('cluster_3_important_bisect', logreg_3_important_bisect), ('cluster_4_important_bisect', logreg_4_important_bisect)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the bisect_combined training set\n",
    "voting_clf.fit(X_train_important_bisect_combined, y_train_important_bisect_combined)\n",
    "\n",
    "# Make predictions using the ensemble model on the bisect_combined test set\n",
    "ensemble_predictions_important_bisect = voting_clf.predict(X_test_important_bisect_combined)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble_important_bisect = accuracy_score(y_test_important_bisect_combined, ensemble_predictions_important_bisect)\n",
    "\n",
    "# Calculate precision\n",
    "precision_ensemble_important_bisect = precision_score(y_test_important_bisect_combined, ensemble_predictions_important_bisect, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_ensemble_important_bisect = recall_score(y_test_important_bisect_combined, ensemble_predictions_important_bisect, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_ensemble_important_bisect = f1_score(y_test_important_bisect_combined, ensemble_predictions_important_bisect, average='weighted')\n",
    "\n",
    "classification_report_ensemble_important_bisect = classification_report(y_test_important_bisect_combined, ensemble_predictions_important_bisect)\n",
    "\n",
    "print(f\"Ensemble Bisect Model Accuracy: {accuracy_ensemble_important_bisect}\")\n",
    "print(f\"Ensemble Bisect Model Precision: {precision_ensemble_important_bisect}\")\n",
    "print(f\"Ensemble Bisect Model Recall: {recall_ensemble_important_bisect}\")\n",
    "print(f\"Ensemble Bisect Model F1-score: {f1_ensemble_important_bisect}\")\n",
    "\n",
    "\n",
    "print(\"Ensemble Bisect Model Classification Report:\")\n",
    "print(classification_report_ensemble_important_bisect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ad21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='soft')\n",
    "\n",
    "# Fit the VotingClassifier on the bisect_combined training set\n",
    "voting_clf.fit(X_train_important_bisect_combined, y_train_important_bisect_combined)\n",
    "\n",
    "\n",
    "# Calculate predicted probabilities for each class\n",
    "ensemble_probabilities = voting_clf.predict_proba(X_test_important_bisect_combined)\n",
    "\n",
    "# Extract the predicted probabilities for the positive class (class 1)\n",
    "positive_class_probabilities = ensemble_probabilities[:, 1]\n",
    "\n",
    "# Calculate the AUC-ROC score\n",
    "auc_roc = roc_auc_score(y_test_important_bisect_combined, positive_class_probabilities)\n",
    "\n",
    "print(f\"AUC-ROC Score: {auc_roc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61de63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_important_bisect, x='blood_glucose_level', y='age', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus Age')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_important_bisect, x='blood_glucose_level', y='HbA1c_level', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus HbA1c Level')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('HbA1c Level')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a77f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_important_bisect, x='blood_glucose_level', y='age', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus Age')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc9518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
