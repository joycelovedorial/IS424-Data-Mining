{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a71b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import BisectingKMeans\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.utils import resample\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f960efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>smoking_history_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247356</td>\n",
       "      <td>-0.128959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247356</td>\n",
       "      <td>-0.128959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.247356</td>\n",
       "      <td>0.160772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.452953</td>\n",
       "      <td>-0.128959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.452953</td>\n",
       "      <td>0.160772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hypertension  heart_disease    bmi  HbA1c_level  blood_glucose_level  \\\n",
       "0  80.0             0              1  25.19          6.6                  140   \n",
       "1  54.0             0              0  27.32          6.6                   80   \n",
       "2  28.0             0              0  27.32          5.7                  158   \n",
       "3  36.0             0              0  23.45          5.0                  155   \n",
       "4  76.0             1              1  20.14          4.8                  155   \n",
       "\n",
       "   diabetes  smoking_history_encoded  gender_encoded  \n",
       "0         0                -0.247356       -0.128959  \n",
       "1         0                -0.247356       -0.128959  \n",
       "2         0                -0.247356        0.160772  \n",
       "3         0                 0.452953       -0.128959  \n",
       "4         0                 0.452953        0.160772  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/Users/varalam/Downloads/Original Dataset without Outliers.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56cda6",
   "metadata": {},
   "source": [
    "<h1>SMOTE Oversampling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af33709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes:  5736\n",
      "No:  90572\n"
     ]
    }
   ],
   "source": [
    "is_diabetic = df[\"diabetes\"].value_counts()\n",
    "print(\"Yes: \",is_diabetic[1])\n",
    "print(\"No: \",is_diabetic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "880b287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy of df before doing SMOTE oversampling\n",
    "new_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eacd9c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = new_df.drop(\"diabetes\", axis=1)\n",
    "y = new_df[\"diabetes\"]\n",
    "\n",
    "# Initialize SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=424)\n",
    "\n",
    "# Apply SMOTE to the dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Count the occurrences of each class in the original dataset\n",
    "original_class_counts = new_df[\"diabetes\"].value_counts()\n",
    "\n",
    "# Calculate the percentage of each class\n",
    "original_percentages = original_class_counts / len(new_df) * 100\n",
    "\n",
    "# Count the occurrences of each class in the resampled dataset\n",
    "resampled_class_counts = pd.Series(y_resampled).value_counts()\n",
    "\n",
    "# Calculate the percentage of each class\n",
    "resampled_percentages = resampled_class_counts / len(y_resampled) * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Bar chart for original and SMOTE resampled class distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "bars_1 = plt.bar(original_class_counts.index, original_class_counts.values, color=['violet', 'yellow'])\n",
    "for bar, label in zip(bars_1, original_percentages):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5, f'{label:.2f}%', ha='center', va='bottom')\n",
    "plt.title('Original Diabetes Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(original_class_counts.index, ['0', '1'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "bars_2 = plt.bar(resampled_class_counts.index, resampled_class_counts.values, color=['violet', 'yellow'])\n",
    "for bar, label in zip(bars_2, resampled_percentages):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5, f'{label:.2f}%', ha='center', va='bottom')\n",
    "plt.title('SMOTE Resampled Diabetes Class Distribution for Dataframe Without Outliers')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b0ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the SMOTE resampled data\n",
    "df_resampled = pd.DataFrame(data=X_resampled, columns=X.columns)\n",
    "df_resampled[\"diabetes\"] = y_resampled\n",
    "\n",
    "df_resampled_bisect = df_resampled.copy()\n",
    "df_resampled_imp = df_resampled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039ba0a",
   "metadata": {},
   "source": [
    "<h1>KMeans Clustering<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29bdc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_resampled.iloc[:, 0:8]\n",
    "y = df_resampled.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72338a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit KMeans model\n",
    "model=KMeans(n_clusters=4, n_init=10, random_state=424)\n",
    "model.fit(X)\n",
    "\n",
    "labels=model.labels_ + 1\n",
    "labels  #clustering into 2 groups: 0 and 1\n",
    "\n",
    "centers=model.cluster_centers_\n",
    "centers\n",
    "\n",
    "model.inertia_\n",
    "\n",
    "X['clusters']=labels\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa58bd",
   "metadata": {},
   "source": [
    "<h1>Elbow Plot of KMeans Clustering<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c77392",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia_train={}\n",
    "for n_cluster in range(1,10):\n",
    "    model=KMeans(n_clusters=n_cluster, n_init=10)\n",
    "    model.fit(X)\n",
    "    inertia_train[n_cluster]=model.inertia_\n",
    "    \n",
    "plt.plot(range(1,10),inertia_train.values())\n",
    "plt.xlabel('The number of clusters') #inertia is the measure of each dots to its centers: tight clusters, low inertia\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7f60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the 'clusters' column to the original DataFrame\n",
    "df_resampled['clusters'] = X['clusters']\n",
    "\n",
    "# Display the DataFrame with added 'clusters' column\n",
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6652841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over unique cluster values\n",
    "for cluster_value in df_resampled['clusters'].unique():\n",
    "    # Create a DataFrame for the current cluster\n",
    "    cluster_idx = df_resampled[df_resampled['clusters'] == cluster_value].copy()\n",
    "    \n",
    "    # Create a variable for the current DataFrame\n",
    "    globals()[f'cluster_{cluster_value}'] = cluster_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ca9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef9015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_1 = cluster_1.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_1 = X_cluster_1.drop('clusters', axis = 1)\n",
    "y_cluster_1 = cluster_1['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_1, X_test_cluster_1, y_train_cluster_1, y_test_cluster_1 = train_test_split(X_cluster_1, y_cluster_1, test_size=0.3, random_state=414)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_1 = LogisticRegression(random_state=414)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_1.fit(X_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_1 = logreg_1.predict(X_test_cluster_1)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_1, predictions_1)\n",
    "classification_rep = classification_report(y_test_cluster_1, predictions_1)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_2 = cluster_2.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_2 = X_cluster_2.drop('clusters', axis = 1)\n",
    "y_cluster_2 = cluster_2['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_2, X_test_cluster_2, y_train_cluster_2, y_test_cluster_2 = train_test_split(X_cluster_2, y_cluster_2, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_2 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_2.fit(X_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_2 = logreg_2.predict(X_test_cluster_2)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_2, predictions_2)\n",
    "classification_rep = classification_report(y_test_cluster_2, predictions_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_3 = cluster_3.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_3 = X_cluster_3.drop('clusters', axis = 1)\n",
    "y_cluster_3 = cluster_3['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_3, X_test_cluster_3, y_train_cluster_3, y_test_cluster_3 = train_test_split(X_cluster_3, y_cluster_3, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_3 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_3.fit(X_train_cluster_3, y_train_cluster_3)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_3 = logreg_3.predict(X_test_cluster_3)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_3, predictions_3)\n",
    "classification_rep = classification_report(y_test_cluster_3, predictions_3)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Combine features and labels from all clusters\n",
    "X_combined = np.concatenate((X_cluster_1, X_cluster_3, X_cluster_2, X_cluster_4), axis=0)\n",
    "y_combined = np.concatenate((y_cluster_1, y_cluster_3, y_cluster_2, y_cluster_4), axis=0)\n",
    "\n",
    "# Split the combined data into training and test sets\n",
    "X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(X_combined, y_combined, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1', logreg_1), ('cluster_3', logreg_3), ('cluster_2', logreg_2), ('cluster_4', logreg_4)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the combined training set\n",
    "voting_clf.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Make predictions using the ensemble model on the combined test set\n",
    "ensemble_predictions = voting_clf.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y_test_combined, ensemble_predictions)\n",
    "# Calculate precision\n",
    "precision_ensemble = precision_score(y_test_combined, ensemble_predictions, average='weighted')\n",
    "# Calculate recall\n",
    "recall_ensemble = recall_score(y_test_combined, ensemble_predictions, average='weighted')\n",
    "# Calculate F1-score\n",
    "f1_ensemble = f1_score(y_test_combined, ensemble_predictions, average='weighted')\n",
    "# Calculate the AUC score\n",
    "auc_ensemble = roc_auc_score(y_test_combined, ensemble_predictions)\n",
    "\n",
    "\n",
    "classification_report_ensemble = classification_report(y_test_combined, ensemble_predictions)\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble}\")\n",
    "print(f\"Ensemble Model Precision: {precision_ensemble}\")\n",
    "print(f\"Ensemble Model Recall: {recall_ensemble}\")\n",
    "print(f\"Ensemble Model f1: {f1_ensemble}\")\n",
    "print(f\"Ensemble Model AUC ROC: {auc_ensemble}\")\n",
    "print(\"Ensemble Model Classification Report:\")\n",
    "print(classification_report_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b278b1",
   "metadata": {},
   "source": [
    "<h1>Random Forests model on clusters<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7217204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the first Random Forest model\n",
    "rf_model1 = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model1.fit(X_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf1 = rf_model1.predict(X_test_cluster_1)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf1 = accuracy_score(y_test_cluster_1, y_pred_rf1)\n",
    "print(\"Random Forest Model 1 Accuracy:\", accuracy_rf1)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_1, y_pred_rf1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model1, X_train_cluster_1, y_train_cluster_1, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8958115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the first Random Forest model\n",
    "rf_model2 = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model2.fit(X_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf2 = rf_model2.predict(X_test_cluster_2)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf2 = accuracy_score(y_test_cluster_2, y_pred_rf2)\n",
    "print(\"Random Forest Model 1 Accuracy:\", accuracy_rf2)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_2, y_pred_rf2)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model2, X_train_cluster_2, y_train_cluster_2, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06904cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the first Random Forest model\n",
    "rf_model3 = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model3.fit(X_train_cluster_3, y_train_cluster_3)\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf3 = rf_model3.predict(X_test_cluster_3)\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf3 = accuracy_score(y_test_cluster_3, y_pred_rf3)\n",
    "print(\"Random Forest Model 3 Accuracy:\", accuracy_rf3)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_3, y_pred_rf3)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81506bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the first Random Forest model\n",
    "rf_model4 = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model4.fit(X_train_cluster_4, y_train_cluster_4)\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf4 = rf_model4.predict(X_test_cluster_4)\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf4 = accuracy_score(y_test_cluster_4, y_pred_rf4)\n",
    "print(\"Random Forest Model 4 Accuracy:\", accuracy_rf4)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_4, y_pred_rf4)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4760125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Combine features and labels from all clusters\n",
    "X_combined_rf = np.concatenate((X_cluster_1, X_cluster_2, X_cluster_3, X_cluster_4), axis=0)\n",
    "y_combined_rf = np.concatenate((y_cluster_1, y_cluster_2, y_cluster_3, y_cluster_4), axis=0)\n",
    "\n",
    "# Split the combined_rf data into training and test sets\n",
    "X_train_combined_rf, X_test_combined_rf, y_train_combined_rf, y_test_combined_rf = train_test_split(X_combined_rf, y_combined_rf, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1', rf_model1), ('cluster_2', rf_model2), ('cluster_3', rf_model3), ('cluster_4', rf_model4)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the combined_rf training set\n",
    "voting_clf.fit(X_train_combined_rf, y_train_combined_rf)\n",
    "\n",
    "# Make predictions using the ensemble model on the combined_rf test set\n",
    "ensemble_predictions = voting_clf.predict(X_test_combined_rf)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y_test_combined_rf, ensemble_predictions)\n",
    "\n",
    "\n",
    "# Calculate precision\n",
    "precision_ensemble = precision_score(y_test_combined_rf, ensemble_predictions, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_ensemble = recall_score(y_test_combined_rf, ensemble_predictions, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_ensemble = f1_score(y_test_combined_rf, ensemble_predictions, average='weighted')\n",
    "\n",
    "\n",
    "classification_report_ensemble = classification_report(y_test_combined_rf, ensemble_predictions)\n",
    "\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble}\")\n",
    "print(f\"Ensemble Model Precision: {precision_ensemble}\")\n",
    "print(f\"Ensemble Model Recall: {recall_ensemble}\")\n",
    "print(f\"Ensemble Model F1-score: {f1_ensemble}\")\n",
    "\n",
    "\n",
    "print(\"Ensemble Model Classification Report:\")\n",
    "print(classification_report_ensemble)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a0d0e",
   "metadata": {},
   "source": [
    "<h1>EDA on categorical variables<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef61ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Create a new column 'bmi/age' by dividing 'bmi' by 'age'\n",
    "df_resampled['bmi/age'] = df_resampled['bmi'] / df_resampled['age']\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled, x='age', y='bmi', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Age versus BMI')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('BMI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023dc1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled, x='blood_glucose_level', y='HbA1c_level', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus HbA1c Level')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('HbA1c Level')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff966079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled, x='blood_glucose_level', y='age', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus Age')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b2bc3",
   "metadata": {},
   "source": [
    "<h1> Bisecting KMeans <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3a9e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled_bisect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bisect = df_resampled_bisect.iloc[:, 0:8]\n",
    "y_bisect = df_resampled_bisect.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Instantiate BisectingKMeans with desired number of clusters\n",
    "bkm = BisectingKMeans(n_clusters=4, random_state=424)\n",
    "\n",
    "# Fit the model to the data\n",
    "bkm.fit(X_bisect)\n",
    "\n",
    "\n",
    "\n",
    "# Predict the clusters for the data points\n",
    "labels = bkm.predict(X_bisect) + 1\n",
    "\n",
    "# Print the cluster centers\n",
    "print(\"Cluster centers:\")\n",
    "print(bkm.cluster_centers_)\n",
    "\n",
    "X_bisect['clusters']=labels\n",
    "X_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dee2b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the 'clusters' column to the original DataFrame\n",
    "df_resampled_bisect['clusters'] = X_bisect['clusters']\n",
    "\n",
    "# Display the DataFrame with added 'clusters' column\n",
    "df_resampled_bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413339e",
   "metadata": {},
   "source": [
    "<h1> Logistic Prediction on bisect Cluster groups <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over unique cluster values\n",
    "for cluster_value in df_resampled_bisect['clusters'].unique():\n",
    "    # Create a DataFrame for the current cluster\n",
    "    cluster_idx_bisect = df_resampled_bisect[df_resampled_bisect['clusters'] == cluster_value].copy()\n",
    "    \n",
    "    # Create a variable for the current DataFrame\n",
    "    globals()[f'cluster_{cluster_value}_bisect'] = cluster_idx_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e69294",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_2_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5344e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_1_bisect = cluster_1_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_1_bisect = X_cluster_1_bisect.drop('clusters', axis = 1)\n",
    "y_cluster_1_bisect = cluster_1_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_1_bisect, X_test_cluster_1_bisect, y_train_cluster_1_bisect, y_test_cluster_1_bisect = train_test_split(X_cluster_1_bisect, y_cluster_1_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_1_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_1_bisect.fit(X_train_cluster_1_bisect, y_train_cluster_1_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_1_bisect = logreg_1_bisect.predict(X_test_cluster_1_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_1_bisect, predictions_1_bisect)\n",
    "classification_rep = classification_report(y_test_cluster_1_bisect, predictions_1_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03948355",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_3_bisect = cluster_3_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_3_bisect = X_cluster_3_bisect.drop('clusters', axis = 1)\n",
    "y_cluster_3_bisect = cluster_3_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_3_bisect, X_test_cluster_3_bisect, y_train_cluster_3_bisect, y_test_cluster_3_bisect = train_test_split(X_cluster_3_bisect, y_cluster_3_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_3_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_3_bisect.fit(X_train_cluster_3_bisect, y_train_cluster_3_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_3_bisect = logreg_3_bisect.predict(X_test_cluster_3_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_3_bisect, predictions_3_bisect)\n",
    "classification_rep = classification_report(y_test_cluster_3_bisect, predictions_3_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd579db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_4_bisect = cluster_4_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_cluster_4_bisect = X_cluster_4_bisect.drop('clusters', axis = 1)\n",
    "y_cluster_4_bisect = cluster_4_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_cluster_4_bisect, X_test_cluster_4_bisect, y_train_cluster_4_bisect, y_test_cluster_4_bisect = train_test_split(X_cluster_4_bisect, y_cluster_4_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_4_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_4_bisect.fit(X_train_cluster_4_bisect, y_train_cluster_4_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_4_bisect = logreg_4_bisect.predict(X_test_cluster_4_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_cluster_4_bisect, predictions_4_bisect)\n",
    "classification_rep = classification_report(y_test_cluster_4_bisect, predictions_4_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e8a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Combine features and labels from all clusters\n",
    "X_bisect_combined = np.concatenate((X_cluster_1_bisect, X_cluster_3_bisect, X_cluster_2_bisect, X_cluster_4_bisect), axis=0)\n",
    "y_bisect_combined = np.concatenate((y_cluster_1_bisect, y_cluster_3_bisect, y_cluster_2_bisect, y_cluster_4_bisect), axis=0)\n",
    "\n",
    "# Split the bisect_combined data into training and test sets\n",
    "X_train_bisect_combined, X_test_bisect_combined, y_train_bisect_combined, y_test_bisect_combined = train_test_split(X_bisect_combined, y_bisect_combined, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1_bisect', logreg_1_bisect), ('cluster_2_bisect', logreg_2_bisect), ('cluster_3_bisect', logreg_3_bisect), ('cluster_4_bisect', logreg_4_bisect)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the bisect_combined training set\n",
    "voting_clf.fit(X_train_bisect_combined, y_train_bisect_combined)\n",
    "\n",
    "# Make predictions using the ensemble model on the bisect_combined test set\n",
    "ensemble_predictions_bisect = voting_clf.predict(X_test_bisect_combined)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble_bisect = accuracy_score(y_test_bisect_combined, ensemble_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision_ensemble_bisect = precision_score(y_test_bisect_combined, ensemble_predictions_bisect, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_ensemble_bisect = recall_score(y_test_bisect_combined, ensemble_predictions_bisect, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_ensemble_bisect = f1_score(y_test_bisect_combined, ensemble_predictions_bisect, average='weighted')\n",
    "\n",
    "classification_report_ensemble_bisect = classification_report(y_test_bisect_combined, ensemble_predictions_bisect)\n",
    "\n",
    "print(f\"Ensemble Bisect Model Accuracy: {accuracy_ensemble_bisect}\")\n",
    "print(f\"Ensemble Bisect Model Precision: {precision_ensemble_bisect}\")\n",
    "print(f\"Ensemble Bisect Model Recall: {recall_ensemble_bisect}\")\n",
    "print(f\"Ensemble Bisect Model F1-score: {f1_ensemble_bisect}\")\n",
    "\n",
    "\n",
    "print(\"Ensemble Bisect Model Classification Report:\")\n",
    "print(classification_report_ensemble_bisect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81277fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='soft')\n",
    "\n",
    "# Fit the VotingClassifier on the bisect_combined training set\n",
    "voting_clf.fit(X_train_bisect_combined, y_train_bisect_combined)\n",
    "\n",
    "\n",
    "# Calculate predicted probabilities for each class\n",
    "ensemble_probabilities = voting_clf.predict_proba(X_test_bisect_combined)\n",
    "\n",
    "# Extract the predicted probabilities for the positive class (class 1)\n",
    "positive_class_probabilities = ensemble_probabilities[:, 1]\n",
    "\n",
    "# Calculate the AUC-ROC score\n",
    "auc_roc = roc_auc_score(y_test_bisect_combined, positive_class_probabilities)\n",
    "\n",
    "print(f\"AUC-ROC Score: {auc_roc}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce05702",
   "metadata": {},
   "source": [
    "<h1>Random Forests model on bisect clusters<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_cluster_1_bisect, X_test_cluster_1_bisect, y_train_cluster_1_bisect, y_test_cluster_1_bisect = train_test_split(X_cluster_1_bisect, y_cluster_1_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "\n",
    "# Create and train the first Random Forest model\n",
    "rf_model1_bisect = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model1_bisect.fit(X_train_cluster_1_bisect, y_train_cluster_1_bisect)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf1_bisect = rf_model1_bisect.predict(X_test_cluster_1_bisect)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf1_bisect = accuracy_score(y_test_cluster_1_bisect, y_pred_rf1_bisect)\n",
    "print(\"Random Forest Model 1 Bisect Accuracy:\", accuracy_rf1_bisect)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_1_bisect, y_pred_rf1_bisect)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model1_bisect, X_train_cluster_1_bisect, y_train_cluster_1_bisect, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Biscet Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Bisect Accuracy:\", cv_scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e03368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_cluster_2_bisect, X_test_cluster_2_bisect, y_train_cluster_2_bisect, y_test_cluster_2_bisect = train_test_split(X_cluster_2_bisect, y_cluster_2_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "\n",
    "# Create and train the first Random Forest model\n",
    "rf_model2_bisect = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model2_bisect.fit(X_train_cluster_2_bisect, y_train_cluster_2_bisect)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf2_bisect = rf_model2_bisect.predict(X_test_cluster_2_bisect)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf2_bisect = accuracy_score(y_test_cluster_2_bisect, y_pred_rf2_bisect)\n",
    "print(\"Random Forest Model 2 Bisect Accuracy:\", accuracy_rf2_bisect)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_2_bisect, y_pred_rf2_bisect)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model2_bisect, X_train_cluster_2_bisect, y_train_cluster_2_bisect, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Biscet Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Bisect Accuracy:\", cv_scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_cluster_3_bisect, X_test_cluster_3_bisect, y_train_cluster_3_bisect, y_test_cluster_3_bisect = train_test_split(X_cluster_3_bisect, y_cluster_3_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "\n",
    "# Create and train the first Random Forest model\n",
    "rf_model3_bisect = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model3_bisect.fit(X_train_cluster_3_bisect, y_train_cluster_3_bisect)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf3_bisect = rf_model3_bisect.predict(X_test_cluster_3_bisect)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf3_bisect = accuracy_score(y_test_cluster_3_bisect, y_pred_rf3_bisect)\n",
    "print(\"Random Forest Model 3 Bisect Accuracy:\", accuracy_rf3_bisect)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_3_bisect, y_pred_rf3_bisect)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model3_bisect, X_train_cluster_3_bisect, y_train_cluster_3_bisect, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Biscet Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Bisect Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train_cluster_4_bisect, X_test_cluster_4_bisect, y_train_cluster_4_bisect, y_test_cluster_4_bisect = train_test_split(X_cluster_4_bisect, y_cluster_4_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "\n",
    "# Create and train the first Random Forest model\n",
    "rf_model4_bisect = RandomForestClassifier(n_estimators=100, random_state=424)\n",
    "rf_model4_bisect.fit(X_train_cluster_4_bisect, y_train_cluster_4_bisect)\n",
    "\n",
    "\n",
    "# Make predictions using the first Random Forest model\n",
    "y_pred_rf4_bisect = rf_model4_bisect.predict(X_test_cluster_4_bisect)\n",
    "\n",
    "\n",
    "# Calculate accuracy for the first Random Forest model\n",
    "accuracy_rf4_bisect = accuracy_score(y_test_cluster_4_bisect, y_pred_rf4_bisect)\n",
    "print(\"Random Forest Model 4 Bisect Accuracy:\", accuracy_rf4_bisect)\n",
    "\n",
    "classification_rep = classification_report(y_test_cluster_4_bisect, y_pred_rf4_bisect)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(rf_model4_bisect, X_train_cluster_4_bisect, y_train_cluster_4_bisect, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validated Biscet Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Cross-validated Bisect Accuracy:\", cv_scores.mean())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ea541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine features and labels from all clusters\n",
    "X_bisect_combined_rf = np.concatenate((X_cluster_1_bisect, X_cluster_2_bisect, X_cluster_3_bisect, X_cluster_4_bisect), axis=0)\n",
    "y_bisect_combined_rf = np.concatenate((y_cluster_1_bisect, y_cluster_2_bisect, y_cluster_3_bisect, y_cluster_4_bisect), axis=0)\n",
    "\n",
    "# Split the combined_rf data into training and test sets\n",
    "X_train_combined_rf_bisect, X_test_combined_rf_bisect, y_train_combined_rf_bisect, y_test_combined_rf_bisect = train_test_split(X_bisect_combined_rf, y_bisect_combined_rf, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1_bisect', rf_model1_bisect), ('cluster_2_bisect', rf_model2_bisect), ('cluster_3_bisect', rf_model3_bisect), ('cluster_4_bisect', rf_model4_bisect)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the combined_rf training set\n",
    "voting_clf.fit(X_train_combined_rf_bisect, y_train_combined_rf_bisect)\n",
    "\n",
    "# Make predictions using the ensemble model on the combined_rf test set\n",
    "ensemble_predictions = voting_clf.predict(X_test_combined_rf_bisect)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y_test_combined_rf_bisect, ensemble_predictions)\n",
    "\n",
    "# Calculate precision\n",
    "precision_ensemble = precision_score(y_test_combined_rf_bisect, ensemble_predictions, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_ensemble = recall_score(y_test_combined_rf_bisect, ensemble_predictions, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_ensemble = f1_score(y_test_combined_rf_bisect, ensemble_predictions, average='weighted')\n",
    "\n",
    "classification_report_ensemble = classification_report(y_test_combined_rf_bisect, ensemble_predictions)\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble}\")\n",
    "print(f\"Ensemble Model Precision: {precision_ensemble}\")\n",
    "print(f\"Ensemble Model Recall: {recall_ensemble}\")\n",
    "print(f\"Ensemble Model F1-score: {f1_ensemble}\")\n",
    "\n",
    "\n",
    "print(\"Ensemble Model Classification Report:\")\n",
    "print(classification_report_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3942c667",
   "metadata": {},
   "source": [
    "<h1>EDA on categorical variables bisect df<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c622551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Create a new column 'bmi/age' by dividing 'bmi' by 'age'\n",
    "df_resampled_bisect['bmi/age'] = df_resampled_bisect['bmi'] / df_resampled_bisect['age']\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled_bisect, x='age', y='bmi', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Age versus BMI')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('BMI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled_bisect, x='blood_glucose_level', y='HbA1c_level', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus HbA1c Level')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('HbA1c Level')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pal is a predefined color palette with at least 4 colors\n",
    "pal = sns.color_palette('Set3', 4)\n",
    "\n",
    "# Plot clusters using scatterplot\n",
    "sns.scatterplot(data=df_resampled_bisect, x='blood_glucose_level', y='age', hue='clusters', palette=pal)\n",
    "plt.title('Clusters of Patients by Blood Glucose Level versus Age')\n",
    "plt.xlabel('Blood Glucose Level')\n",
    "plt.ylabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b470823",
   "metadata": {},
   "source": [
    "<h1> Features Importance Incorporated <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccdbae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled_imp = df_resampled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9611ba7",
   "metadata": {},
   "source": [
    "<h1>K-Means Important Clustering <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c44845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"hypertension\", \"heart_disease\", \"smoking_history_encoded\", \"gender_encoded\"]\n",
    "df_resesampled_imp = df_resampled.copy()\n",
    "df_resampled_imp = df_resampled_imp.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "df_important_bisect = df_resampled_imp.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad02809",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important = df_resampled_imp.iloc[:, 0:4]\n",
    "y = df_resampled_imp.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit KMeans model\n",
    "model=KMeans(n_clusters=4, n_init=10, random_state=424)\n",
    "model.fit(X_important)\n",
    "\n",
    "labels=model.labels_ + 1\n",
    "labels  #clustering into 2 groups: 0 and 1\n",
    "\n",
    "centers=model.cluster_centers_\n",
    "centers\n",
    "\n",
    "model.inertia_\n",
    "\n",
    "X_important['clusters']=labels\n",
    "X_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cce9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia_train={}\n",
    "for n_cluster in range(1,10):\n",
    "    model=KMeans(n_clusters=n_cluster, n_init=10, random_state =424)\n",
    "    model.fit(X_important)\n",
    "    inertia_train[n_cluster]=model.inertia_\n",
    "    \n",
    "plt.plot(range(1,10),inertia_train.values())\n",
    "plt.xlabel('The number of clusters with important') #inertia is the measure of each dots to its centers: tight clusters, low inertia\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18972713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the 'clusters' column to the original DataFrame\n",
    "df_resampled_imp['clusters'] = X_important['clusters']\n",
    "\n",
    "# Display the DataFrame with added 'clusters' column\n",
    "df_resampled_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3784c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_1 = df_resampled_imp[df_resampled_imp[\"clusters\"] == 1]\n",
    "important_2 = df_resampled_imp[df_resampled_imp[\"clusters\"] == 2]\n",
    "important_3 = df_resampled_imp[df_resampled_imp[\"clusters\"] == 3]\n",
    "important_4 = df_resampled_imp[df_resampled_imp[\"clusters\"] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9fd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_2 = important_2.drop('diabetes', axis=1)  # Features\n",
    "X_important_2 = X_important_2.drop('clusters', axis = 1)\n",
    "y_important_2 = important_2['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_important_2, X_test_important_2, y_train_important_2, y_test_important_2 = train_test_split(X_important_2, y_important_2, test_size=0.1, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_2 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_2.fit(X_train_important_2, y_train_important_2)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_2 = logreg_2.predict(X_test_important_2)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_important_2, predictions_2)\n",
    "classification_rep = classification_report(y_test_important_2, predictions_2)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_3 = important_3.drop('diabetes', axis=1)  # Features\n",
    "X_important_3 = X_important_3.drop('clusters', axis = 1)\n",
    "y_important_3 = important_3['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_important_3, X_test_important_3, y_train_important_3, y_test_important_3 = train_test_split(X_important_3, y_important_3, test_size=0.1, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_3 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_3.fit(X_train_important_3, y_train_important_3)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_3 = logreg_3.predict(X_test_important_3)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_important_3, predictions_3)\n",
    "classification_rep = classification_report(y_test_important_3, predictions_3)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be539fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_important_4 = important_4.drop('diabetes', axis=1)  # Features\n",
    "X_important_4 = X_important_4.drop('clusters', axis = 1)\n",
    "y_important_4 = important_4['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_important_4, X_test_important_4, y_train_important_4, y_test_important_4 = train_test_split(X_important_4, y_important_4, test_size=0.1, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_4 = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_4.fit(X_train_important_4, y_train_important_4)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_4 = logreg_4.predict(X_test_important_4)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_important_4, predictions_4)\n",
    "classification_rep = classification_report(y_test_important_4, predictions_4)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b013d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Combine features and labels from all importants\n",
    "X_combined_important = np.concatenate((X_important_1, X_important_3, X_important_2, X_important_4), axis=0)\n",
    "y_combined_important = np.concatenate((y_important_1, y_important_3, y_important_2, y_important_4), axis=0)\n",
    "\n",
    "# Split the combined_important data into training and test sets\n",
    "X_train_combined_important, X_test_combined_important, y_train_combined_important, y_test_combined_important = train_test_split(X_combined_important, y_combined_important, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('important_1', logreg_1), ('important_3', logreg_3), ('important_2', logreg_2), ('important_4', logreg_4)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the combined_important training set\n",
    "voting_clf.fit(X_train_combined_important, y_train_combined_important)\n",
    "\n",
    "# Make predictions using the ensemble model on the combined_important test set\n",
    "ensemble_predictions = voting_clf.predict(X_test_combined_important)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble = accuracy_score(y_test_combined_important, ensemble_predictions)\n",
    "# Calculate precision\n",
    "precision_ensemble = precision_score(y_test_combined_important, ensemble_predictions, average='weighted')\n",
    "# Calculate recall\n",
    "recall_ensemble = recall_score(y_test_combined_important, ensemble_predictions, average='weighted')\n",
    "# Calculate F1-score\n",
    "f1_ensemble = f1_score(y_test_combined_important, ensemble_predictions, average='weighted')\n",
    "# Calculate the AUC score\n",
    "auc_ensemble = roc_auc_score(y_test_combined_important, ensemble_predictions)\n",
    "\n",
    "\n",
    "classification_report_ensemble = classification_report(y_test_combined_important, ensemble_predictions)\n",
    "\n",
    "print(f\"Ensemble Model Accuracy: {accuracy_ensemble}\")\n",
    "print(f\"Ensemble Model Precision: {precision_ensemble}\")\n",
    "print(f\"Ensemble Model Recall: {recall_ensemble}\")\n",
    "print(f\"Ensemble Model f1: {f1_ensemble}\")\n",
    "print(f\"Ensemble Model AUC ROC: {auc_ensemble}\")\n",
    "print(\"Ensemble Model Classification Report:\")\n",
    "print(classification_report_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4231fbfa",
   "metadata": {},
   "source": [
    "<h1>Bisect K-Means Important Clustering <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e140dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers:\n",
      "[[ 58.0580045   30.35091927   6.34855261 224.94273842]\n",
      " [ 39.27082082  26.43591273   5.40085941  89.59639399]\n",
      " [ 64.09938153  30.16837961   6.17093711 145.44157819]\n",
      " [ 26.25194945  26.5948089    5.62398065 146.73646823]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>25.190000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>158</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>23.450000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>20.140000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>155</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181139</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>29.697769</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181140</th>\n",
       "      <td>27.965794</td>\n",
       "      <td>38.725452</td>\n",
       "      <td>7.258552</td>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181141</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>27.065110</td>\n",
       "      <td>6.665847</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>67.449624</td>\n",
       "      <td>38.621165</td>\n",
       "      <td>6.024812</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181143</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>27.724526</td>\n",
       "      <td>6.037765</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181144 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        bmi  HbA1c_level  blood_glucose_level  clusters\n",
       "0       80.000000  25.190000     6.600000                  140         3\n",
       "1       54.000000  27.320000     6.600000                   80         2\n",
       "2       28.000000  27.320000     5.700000                  158         4\n",
       "3       36.000000  23.450000     5.000000                  155         4\n",
       "4       76.000000  20.140000     4.800000                  155         3\n",
       "...           ...        ...          ...                  ...       ...\n",
       "181139  79.000000  29.697769     7.000000                  260         1\n",
       "181140  27.965794  38.725452     7.258552                  145         4\n",
       "181141  58.000000  27.065110     6.665847                  220         1\n",
       "181142  67.449624  38.621165     6.024812                  240         1\n",
       "181143  70.000000  27.724526     6.037765                  140         3\n",
       "\n",
       "[181144 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_important_bisect = df_important_bisect.iloc[:, 0:4]\n",
    "y_bisect = df_important_bisect.iloc[:, -1]\n",
    "\n",
    "\n",
    "# Instantiate BisectingKMeans with desired number of clusters\n",
    "bkm = BisectingKMeans(n_clusters=4, random_state=424)\n",
    "\n",
    "# Fit the model to the data\n",
    "bkm.fit(X_important_bisect)\n",
    "\n",
    "\n",
    "\n",
    "# Predict the clusters for the data points\n",
    "labels = bkm.predict(X_important_bisect) + 1\n",
    "\n",
    "# Print the cluster centers\n",
    "print(\"Cluster centers:\")\n",
    "print(bkm.cluster_centers_)\n",
    "\n",
    "X_important_bisect['clusters']=labels\n",
    "X_important_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ba8330c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>25.190000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>23.450000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>20.140000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181139</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>29.697769</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181140</th>\n",
       "      <td>27.965794</td>\n",
       "      <td>38.725452</td>\n",
       "      <td>7.258552</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181141</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>27.065110</td>\n",
       "      <td>6.665847</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>67.449624</td>\n",
       "      <td>38.621165</td>\n",
       "      <td>6.024812</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181143</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>27.724526</td>\n",
       "      <td>6.037765</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181144 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        bmi  HbA1c_level  blood_glucose_level  diabetes  \\\n",
       "0       80.000000  25.190000     6.600000                  140         0   \n",
       "1       54.000000  27.320000     6.600000                   80         0   \n",
       "2       28.000000  27.320000     5.700000                  158         0   \n",
       "3       36.000000  23.450000     5.000000                  155         0   \n",
       "4       76.000000  20.140000     4.800000                  155         0   \n",
       "...           ...        ...          ...                  ...       ...   \n",
       "181139  79.000000  29.697769     7.000000                  260         1   \n",
       "181140  27.965794  38.725452     7.258552                  145         1   \n",
       "181141  58.000000  27.065110     6.665847                  220         1   \n",
       "181142  67.449624  38.621165     6.024812                  240         1   \n",
       "181143  70.000000  27.724526     6.037765                  140         1   \n",
       "\n",
       "        clusters  \n",
       "0              3  \n",
       "1              2  \n",
       "2              4  \n",
       "3              4  \n",
       "4              3  \n",
       "...          ...  \n",
       "181139         1  \n",
       "181140         4  \n",
       "181141         1  \n",
       "181142         1  \n",
       "181143         3  \n",
       "\n",
       "[181144 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the 'clusters' column to the original DataFrame\n",
    "df_important_bisect['clusters'] = X_important_bisect['clusters']\n",
    "\n",
    "# Display the DataFrame with added 'clusters' column\n",
    "df_important_bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3517409",
   "metadata": {},
   "source": [
    "<h1> Logistic Prediction on important bisect Cluster groups <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79dca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over unique cluster values\n",
    "for cluster_value in df_important_bisect['clusters'].unique():\n",
    "    # Create a DataFrame for the current cluster\n",
    "    cluster_idx_important_bisect = df_important_bisect[df_important_bisect['clusters'] == cluster_value].copy()\n",
    "    \n",
    "    # Create a variable for the current DataFrame\n",
    "    globals()[f'cluster_{cluster_value}_important_bisect'] = cluster_idx_important_bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18bf8983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9359851363905075\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81      2110\n",
      "           1       0.95      0.97      0.96      9731\n",
      "\n",
      "    accuracy                           0.94     11841\n",
      "   macro avg       0.91      0.87      0.89     11841\n",
      "weighted avg       0.93      0.94      0.93     11841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_1_important_bisect = cluster_1_important_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_1_important_bisect = X_1_important_bisect.drop('clusters', axis = 1)\n",
    "y_1_important_bisect = cluster_1_important_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_1_important_bisect, X_test_1_important_bisect, y_train_1_important_bisect, y_test_1_important_bisect = train_test_split(X_1_important_bisect, y_1_important_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_1_important_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_1_important_bisect.fit(X_train_1_important_bisect, y_train_1_important_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_1_important_bisect = logreg_1_important_bisect.predict(X_test_1_important_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_1_important_bisect, predictions_1_important_bisect)\n",
    "classification_rep = classification_report(y_test_1_important_bisect, predictions_1_important_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298d064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8214926444205238\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.58      0.68      7221\n",
      "           1       0.82      0.94      0.88     15075\n",
      "\n",
      "    accuracy                           0.82     22296\n",
      "   macro avg       0.82      0.76      0.78     22296\n",
      "weighted avg       0.82      0.82      0.81     22296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_3_important_bisect = cluster_3_important_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_3_important_bisect = X_3_important_bisect.drop('clusters', axis = 1)\n",
    "y_3_important_bisect = cluster_3_important_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_3_important_bisect, X_test_3_important_bisect, y_train_3_important_bisect, y_test_3_important_bisect = train_test_split(X_3_important_bisect, y_3_important_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_3_important_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_3_important_bisect.fit(X_train_3_important_bisect, y_train_3_important_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_3_important_bisect = logreg_3_important_bisect.predict(X_test_3_important_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_3_important_bisect, predictions_3_important_bisect)\n",
    "classification_rep = classification_report(y_test_3_important_bisect, predictions_3_important_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74e0b605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8652080652080653\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      9335\n",
      "           1       0.73      0.52      0.61      2320\n",
      "\n",
      "    accuracy                           0.87     11655\n",
      "   macro avg       0.81      0.74      0.76     11655\n",
      "weighted avg       0.86      0.87      0.86     11655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_4_important_bisect = cluster_4_important_bisect.drop('diabetes', axis=1)  # Features\n",
    "X_4_important_bisect = X_4_important_bisect.drop('clusters', axis = 1)\n",
    "y_4_important_bisect = cluster_4_important_bisect['diabetes']  # Target variable\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_4_important_bisect, X_test_4_important_bisect, y_train_4_important_bisect, y_test_4_important_bisect = train_test_split(X_4_important_bisect, y_4_important_bisect, test_size=0.3, random_state=424)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg_4_important_bisect = LogisticRegression(random_state=424)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logreg_4_important_bisect.fit(X_train_4_important_bisect, y_train_4_important_bisect)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_4_important_bisect = logreg_4_important_bisect.predict(X_test_4_important_bisect)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_4_important_bisect, predictions_4_important_bisect)\n",
    "classification_rep = classification_report(y_test_4_important_bisect, predictions_4_important_bisect)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6088eb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Bisect Model Accuracy: 0.8652473134108641\n",
      "Ensemble Bisect Model Precision: 0.8655437089364098\n",
      "Ensemble Bisect Model Recall: 0.8652473134108641\n",
      "Ensemble Bisect Model F1-score: 0.8652148172418345\n",
      "Ensemble Bisect Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86     27111\n",
      "           1       0.86      0.88      0.87     27233\n",
      "\n",
      "    accuracy                           0.87     54344\n",
      "   macro avg       0.87      0.87      0.87     54344\n",
      "weighted avg       0.87      0.87      0.87     54344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Combine features and labels from all clusters\n",
    "X_important_bisect_combined = np.concatenate((X_1_important_bisect, X_3_important_bisect, X_2_important_bisect, X_4_important_bisect), axis=0)\n",
    "y_important_bisect_combined = np.concatenate((y_1_important_bisect, y_3_important_bisect, y_2_important_bisect, y_4_important_bisect), axis=0)\n",
    "\n",
    "# Split the bisect_combined data into training and test sets\n",
    "X_train_important_bisect_combined, X_test_important_bisect_combined, y_train_important_bisect_combined, y_test_important_bisect_combined = train_test_split(X_important_bisect_combined, y_important_bisect_combined, test_size=0.3, random_state=424)\n",
    "\n",
    "# Create a list of tuples where each tuple is (model_name, model_instance)\n",
    "model_tuple_list = [('cluster_1_important_bisect', logreg_1_important_bisect), ('cluster_2_important_bisect', logreg_2_important_bisect), ('cluster_3_important_bisect', logreg_3_important_bisect), ('cluster_4_important_bisect', logreg_4_important_bisect)]\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='hard')\n",
    "\n",
    "# Fit the VotingClassifier on the bisect_combined training set\n",
    "voting_clf.fit(X_train_important_bisect_combined, y_train_important_bisect_combined)\n",
    "\n",
    "# Make predictions using the ensemble model on the bisect_combined test set\n",
    "ensemble_predictions_important_bisect = voting_clf.predict(X_test_important_bisect_combined)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy_ensemble_important_bisect = accuracy_score(y_test_important_bisect_combined, ensemble_predictions_important_bisect)\n",
    "\n",
    "# Calculate precision\n",
    "precision_ensemble_important_bisect = precision_score(y_test_important_bisect_combined, ensemble_predictions_important_bisect, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall_ensemble_important_bisect = recall_score(y_test_important_bisect_combined, ensemble_predictions_important_bisect, average='weighted')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1_ensemble_important_bisect = f1_score(y_test_important_bisect_combined, ensemble_predictions_important_bisect, average='weighted')\n",
    "\n",
    "classification_report_ensemble_important_bisect = classification_report(y_test_important_bisect_combined, ensemble_predictions_important_bisect)\n",
    "\n",
    "print(f\"Ensemble Bisect Model Accuracy: {accuracy_ensemble_important_bisect}\")\n",
    "print(f\"Ensemble Bisect Model Precision: {precision_ensemble_important_bisect}\")\n",
    "print(f\"Ensemble Bisect Model Recall: {recall_ensemble_important_bisect}\")\n",
    "print(f\"Ensemble Bisect Model F1-score: {f1_ensemble_important_bisect}\")\n",
    "\n",
    "\n",
    "print(\"Ensemble Bisect Model Classification Report:\")\n",
    "print(classification_report_ensemble_important_bisect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "788e55d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.9456613514786462\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=model_tuple_list, voting='soft')\n",
    "\n",
    "# Fit the VotingClassifier on the bisect_combined training set\n",
    "voting_clf.fit(X_train_important_bisect_combined, y_train_important_bisect_combined)\n",
    "\n",
    "\n",
    "# Calculate predicted probabilities for each class\n",
    "ensemble_probabilities = voting_clf.predict_proba(X_test_important_bisect_combined)\n",
    "\n",
    "# Extract the predicted probabilities for the positive class (class 1)\n",
    "positive_class_probabilities = ensemble_probabilities[:, 1]\n",
    "\n",
    "# Calculate the AUC-ROC score\n",
    "auc_roc = roc_auc_score(y_test_important_bisect_combined, positive_class_probabilities)\n",
    "\n",
    "print(f\"AUC-ROC Score: {auc_roc}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975906d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
